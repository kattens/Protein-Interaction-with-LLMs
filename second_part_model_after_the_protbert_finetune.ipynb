{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kattens/Protein-Interaction-with-LLMs/blob/main/second_part_model_after_the_protbert_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O1GOBJjjNNw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS-wzrL6thZf",
        "outputId": "08e4cb1c-2f3b-4718-9774-cd9ba22a4460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "CUDA not available\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CUDA not available\")\n",
        "\n",
        "# Set up the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFGekIK-uY21",
        "outputId": "eac62ee2-9f17-4fb8-a968-71bb349433f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD0ew8E8jXFJ"
      },
      "outputs": [],
      "source": [
        "pairs_df = pd.read_csv('/content/drive/MyDrive/Pairs_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate each specified column to a maximum length of 500 characters\n",
        "columns = ['masked_sequence_A', 'masked_sequence_B', 'Sequence_A', 'Sequence_B']\n",
        "for col in columns:\n",
        "    pairs_df[col] = pairs_df[col].apply(lambda x: x[:500] if len(x) > 500 else x)\n",
        "\n",
        "# Find the longest string by length\n",
        "pairs_df['Length'] = pairs_df['masked_sequence_A'].apply(len)\n",
        "longest_string = pairs_df.loc[pairs_df['Length'].idxmax(), 'masked_sequence_A']\n",
        "print(len(longest_string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMXbw_ebK8lb",
        "outputId": "0d08a08a-6abc-454b-ec4d-67c4e5b32819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_df"
      ],
      "metadata": {
        "id": "_vOXgXIWdBB1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "1c060d2d-570b-444b-d51d-2827b1f51435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    pair_id File Name A File Name B  \\\n",
              "0      1H0J      1H0J_A      1H0J_B   \n",
              "1      1H0J      1H0J_A      1H0J_C   \n",
              "2      1H0J      1H0J_B      1H0J_C   \n",
              "3      1H1L      1H1L_B      1H1L_D   \n",
              "4      1H1Y      1H1Y_A      1H1Y_B   \n",
              "..      ...         ...         ...   \n",
              "536    1JTC      1JTC_B      1JTC_D   \n",
              "537    1JTC      1JTC_C      1JTC_D   \n",
              "538    1JTP      1JTP_A      1JTP_L   \n",
              "539    1JTP      1JTP_A      1JTP_M   \n",
              "540    1JTP      1JTP_L      1JTP_M   \n",
              "\n",
              "                                     masked_sequence_A  \\\n",
              "0    ---NKLVP-FYK-CPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...   \n",
              "1    ----KL-----KTCPAGKNLCYKMFMVATP--PVKRGCIDVCPKSS...   \n",
              "2    ----KLV---------------KMFMVATPKVPVKRG----CPKSS...   \n",
              "3    SQTIDKINSCYPLFEQD-YQELFR-KR------DAQ-VQ--FA---...   \n",
              "4    ------SMLSSDFANLAAEADRM-R-------MDIMDGHFVPNLTI...   \n",
              "..                                                 ...   \n",
              "536  HHHHF-----------------------------------------...   \n",
              "537  HH--------------------------ILPDGTVD--------H-...   \n",
              "538  --------------------SC--------P--MG--------ERE...   \n",
              "539  DVQLQASGGGS-----------------IG-YCMGWFRQAPGKER-...   \n",
              "540  KVYGRCELAAA------------SLGN-VCAAKFESNFN-HA-N--...   \n",
              "\n",
              "                                     masked_sequence_B  \\\n",
              "0    ---NKLVPLF-----------YKMFMVATPKVPVKRGCIDVCPKSS...   \n",
              "1    --CNKLVPLFYK----------KMFMVATPKVPVKRG-------SS...   \n",
              "2    ----KLVP--------------KMFMVATPKVPVKR------PKSS...   \n",
              "3    SQTIDKINSCYPLFEQDEYQ-LFR-KR----AHDAQRVQEVFA---...   \n",
              "4    -----PSMLSSDFANLAAEADRM---------MDIMDGHFVPNLTI...   \n",
              "..                                                 ...   \n",
              "536  HHHHF-----------------------------------------...   \n",
              "537  --------------------SNGGHF-RILPDGTVDGTRD--D---...   \n",
              "538  KV-----------------------GNWVCAAK-------------...   \n",
              "539  -------------------------------A----------TNRN...   \n",
              "540  KVYGRCE------------------GN-VCAAKFESNFNTHATNRN...   \n",
              "\n",
              "                                              coords_A  \\\n",
              "0    [(0.6666441154110079, 0.2338360596696657, -0.3...   \n",
              "1    [(0.6666441154110079, 0.2338360596696657, -0.3...   \n",
              "2    [(-0.35362122723998757, 0.09592292335495496, -...   \n",
              "3    [(1.0335813771762299, -0.07467590563123697, 0....   \n",
              "4    [(-0.9165413095431918, -0.872759328495862, 0.2...   \n",
              "..                                                 ...   \n",
              "536  [(-1.6365909302872783, -0.7891050628266867, 0....   \n",
              "537  [(-2.004807697727987, -1.9555466195303108, -0....   \n",
              "538  [(-0.6264680106736783, -0.5317168732427161, -0...   \n",
              "539  [(-0.6264680106736783, -0.5317168732427161, -0...   \n",
              "540  [(-0.12521386043783925, 0.6731528767441878, -0...   \n",
              "\n",
              "                                              coords_B  \\\n",
              "0    [(-0.35362122723998757, 0.09592292335495496, -...   \n",
              "1    [(0.16223801216970127, -0.4052887381516026, 0....   \n",
              "2    [(0.16223801216970127, -0.4052887381516026, 0....   \n",
              "3    [(1.596220592379937, -1.6520011412450177, 0.58...   \n",
              "4    [(-0.5081293394188968, -0.7043022970351518, -1...   \n",
              "..                                                 ...   \n",
              "536  [(-1.6376207763187678, -0.588986676641465, -1....   \n",
              "537  [(-1.6376207763187678, -0.588986676641465, -1....   \n",
              "538  [(-0.12521386043783925, 0.6731528767441878, -0...   \n",
              "539  [(0.4879190177643481, -0.241022180110313, -0.3...   \n",
              "540  [(0.4879190177643481, -0.241022180110313, -0.3...   \n",
              "\n",
              "                                          Embeddings_A  \\\n",
              "0    tensor([ 0.3624, -0.8023, -1.2588,  1.9488, -0...   \n",
              "1    tensor([ 0.3624, -0.8023, -1.2588,  1.9488, -0...   \n",
              "2    tensor([ 0.8819, -0.2896, -0.0102,  0.5890,  0...   \n",
              "3    tensor([ 0.2023,  0.2512, -2.8480,  0.2294, -0...   \n",
              "4    tensor([ 1.1525e-01,  1.9326e+00, -1.5379e-01,...   \n",
              "..                                                 ...   \n",
              "536  tensor([-1.1383, -0.9070, -1.8404, -1.6600,  0...   \n",
              "537  tensor([ 0.2318, -0.2502, -1.1894, -0.6210,  0...   \n",
              "538  tensor([ 0.4172,  0.4715, -0.8095, -0.2510, -0...   \n",
              "539  tensor([ 0.4172,  0.4715, -0.8095, -0.2510, -0...   \n",
              "540  tensor([-3.4528e-01,  3.7102e-01, -7.3307e-01,...   \n",
              "\n",
              "                                            Sequence_A  \\\n",
              "0    LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...   \n",
              "1    LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...   \n",
              "2    LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...   \n",
              "3    SQTIDKINSCYPLFEQDEYQELFRNKRQLEEAHDAQRVQEVFAWTT...   \n",
              "4    AAKIAPSMLSSDFANLAAEADRMVRLGADWLHMDIMDGHFVPNLTI...   \n",
              "..                                                 ...   \n",
              "536  HHHHFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHI...   \n",
              "537  HHHHFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHI...   \n",
              "538  DVQLQASGGGSVQAGGSLRLSCAASGYTIGPYCMGWFRQAPGKERE...   \n",
              "539  DVQLQASGGGSVQAGGSLRLSCAASGYTIGPYCMGWFRQAPGKERE...   \n",
              "540  KVYGRCELAAAMKRLGLDNYRGYSLGNWVCAAKFESNFNTHATNRN...   \n",
              "\n",
              "                                          Embeddings_B  \\\n",
              "0    tensor([ 0.8819, -0.2896, -0.0102,  0.5890,  0...   \n",
              "1    tensor([-0.5326,  1.6610, -1.1897, -0.3621,  0...   \n",
              "2    tensor([-0.5326,  1.6610, -1.1897, -0.3621,  0...   \n",
              "3    tensor([ 1.1608e+00,  1.7323e+00, -1.1385e+00,...   \n",
              "4    tensor([-5.6799e-01,  9.8331e-01,  3.2209e-01,...   \n",
              "..                                                 ...   \n",
              "536  tensor([ 0.5820, -1.1304,  1.0858,  0.1613, -0...   \n",
              "537  tensor([ 0.5820, -1.1304,  1.0858,  0.1613, -0...   \n",
              "538  tensor([-3.4528e-01,  3.7102e-01, -7.3307e-01,...   \n",
              "539  tensor([ 0.9093, -0.0813, -1.3230, -0.4394,  1...   \n",
              "540  tensor([ 0.9093, -0.0813, -1.3230, -0.4394,  1...   \n",
              "\n",
              "                                            Sequence_B  \\\n",
              "0    LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...   \n",
              "1    LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...   \n",
              "2    LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...   \n",
              "3    SQTIDKINSCYPLFEQDEYQELFRNKRQLEEAHDAQRVQEVFAWTT...   \n",
              "4    AAKIAPSMLSSDFANLAAEADRMVRLGADWLHMDIMDGHFVPNLTI...   \n",
              "..                                                 ...   \n",
              "536  HHHHFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHI...   \n",
              "537  HHHHFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHI...   \n",
              "538  KVYGRCELAAAMKRLGLDNYRGYSLGNWVCAAKFESNFNTHATNRN...   \n",
              "539  KVYGRCELAAAMKRLGLDNYRGYSLGNWVCAAKFESNFNTHATNRN...   \n",
              "540  KVYGRCELAAAMKRLGLDNYRGYSLGNWVCAAKFESNFNTHATNRN...   \n",
              "\n",
              "                                  tokenized_sequence_A  \\\n",
              "0    [10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...   \n",
              "1    [10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...   \n",
              "2    [10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...   \n",
              "3    [16, 14, 17, 8, 3, 9, 8, 12, 16, 2, 20, 13, 10...   \n",
              "4    [1, 1, 9, 8, 1, 13, 16, 11, 10, 16, 16, 3, 5, ...   \n",
              "..                                                 ...   \n",
              "536  [7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...   \n",
              "537  [7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...   \n",
              "538  [3, 18, 14, 10, 14, 1, 16, 6, 6, 6, 16, 18, 14...   \n",
              "539  [3, 18, 14, 10, 14, 1, 16, 6, 6, 6, 16, 18, 14...   \n",
              "540  [9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...   \n",
              "\n",
              "                                  tokenized_sequence_B  \\\n",
              "0    [10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...   \n",
              "1    [10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...   \n",
              "2    [10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...   \n",
              "3    [16, 14, 17, 8, 3, 9, 8, 12, 16, 2, 20, 13, 10...   \n",
              "4    [1, 1, 9, 8, 1, 13, 16, 11, 10, 16, 16, 3, 5, ...   \n",
              "..                                                 ...   \n",
              "536  [7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...   \n",
              "537  [7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...   \n",
              "538  [9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...   \n",
              "539  [9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...   \n",
              "540  [9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...   \n",
              "\n",
              "                           tokenized_masked_sequence_A  \\\n",
              "0    [0, 0, 0, 12, 9, 10, 18, 13, 0, 5, 20, 9, 0, 2...   \n",
              "1    [0, 0, 0, 0, 9, 10, 0, 0, 0, 0, 0, 9, 17, 2, 1...   \n",
              "2    [0, 0, 0, 0, 9, 10, 18, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
              "3    [16, 14, 17, 8, 3, 9, 8, 12, 16, 2, 20, 13, 10...   \n",
              "4    [0, 0, 0, 0, 0, 0, 16, 11, 10, 16, 16, 3, 5, 1...   \n",
              "..                                                 ...   \n",
              "536  [7, 7, 7, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "537  [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "538  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "539  [3, 18, 14, 10, 14, 1, 16, 6, 6, 6, 16, 0, 0, ...   \n",
              "540  [9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 0, 0, 0,...   \n",
              "\n",
              "                           tokenized_masked_sequence_B  \\\n",
              "0    [0, 0, 0, 12, 9, 10, 18, 13, 10, 5, 0, 0, 0, 0...   \n",
              "1    [0, 0, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 0, ...   \n",
              "2    [0, 0, 0, 0, 9, 10, 18, 13, 0, 0, 0, 0, 0, 0, ...   \n",
              "3    [16, 14, 17, 8, 3, 9, 8, 12, 16, 2, 20, 13, 10...   \n",
              "4    [0, 0, 0, 0, 0, 13, 16, 11, 10, 16, 16, 3, 5, ...   \n",
              "..                                                 ...   \n",
              "536  [7, 7, 7, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "537  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "538  [9, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
              "539  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "540  [9, 18, 20, 6, 15, 2, 4, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                              sum_tokenized_sequence_A  \\\n",
              "0    [10, 9, 2, 24, 18, 20, 36, 26, 10, 10, 40, 18,...   \n",
              "1    [10, 9, 2, 12, 18, 20, 18, 13, 10, 5, 20, 18, ...   \n",
              "2    [10, 9, 2, 12, 18, 20, 36, 13, 10, 5, 20, 9, 1...   \n",
              "3    [32, 28, 34, 16, 6, 18, 16, 24, 32, 4, 40, 26,...   \n",
              "4    [1, 1, 9, 8, 1, 13, 32, 22, 20, 32, 32, 6, 10,...   \n",
              "..                                                 ...   \n",
              "536  [14, 14, 14, 14, 10, 12, 10, 13, 13, 6, 12, 20...   \n",
              "537  [14, 14, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9...   \n",
              "538  [3, 18, 14, 10, 14, 1, 16, 6, 6, 6, 16, 18, 14...   \n",
              "539  [6, 36, 28, 20, 28, 2, 32, 12, 12, 12, 32, 18,...   \n",
              "540  [18, 36, 40, 12, 30, 4, 8, 20, 2, 2, 2, 11, 9,...   \n",
              "\n",
              "                              sum_tokenized_sequence_B  Length  \n",
              "0    [10, 9, 2, 24, 18, 20, 36, 26, 20, 10, 20, 9, ...      60  \n",
              "1    [10, 9, 4, 24, 18, 20, 36, 26, 20, 10, 40, 18,...      60  \n",
              "2    [10, 9, 2, 12, 18, 20, 36, 26, 10, 5, 20, 9, 1...      60  \n",
              "3    [32, 28, 34, 16, 6, 18, 16, 24, 32, 4, 40, 26,...     500  \n",
              "4    [1, 1, 9, 8, 1, 26, 32, 22, 20, 32, 32, 6, 10,...     219  \n",
              "..                                                 ...     ...  \n",
              "536  [14, 14, 14, 14, 10, 12, 10, 13, 13, 6, 12, 20...     141  \n",
              "537  [7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...     141  \n",
              "538  [18, 36, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, ...     135  \n",
              "539  [9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...     135  \n",
              "540  [18, 36, 40, 12, 30, 4, 8, 10, 1, 1, 1, 11, 9,...     129  \n",
              "\n",
              "[541 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa1f6f01-6838-43e6-ba4f-b96847224c0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pair_id</th>\n",
              "      <th>File Name A</th>\n",
              "      <th>File Name B</th>\n",
              "      <th>masked_sequence_A</th>\n",
              "      <th>masked_sequence_B</th>\n",
              "      <th>coords_A</th>\n",
              "      <th>coords_B</th>\n",
              "      <th>Embeddings_A</th>\n",
              "      <th>Sequence_A</th>\n",
              "      <th>Embeddings_B</th>\n",
              "      <th>Sequence_B</th>\n",
              "      <th>tokenized_sequence_A</th>\n",
              "      <th>tokenized_sequence_B</th>\n",
              "      <th>tokenized_masked_sequence_A</th>\n",
              "      <th>tokenized_masked_sequence_B</th>\n",
              "      <th>sum_tokenized_sequence_A</th>\n",
              "      <th>sum_tokenized_sequence_B</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1H0J</td>\n",
              "      <td>1H0J_A</td>\n",
              "      <td>1H0J_B</td>\n",
              "      <td>---NKLVP-FYK-CPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...</td>\n",
              "      <td>---NKLVPLF-----------YKMFMVATPKVPVKRGCIDVCPKSS...</td>\n",
              "      <td>[(0.6666441154110079, 0.2338360596696657, -0.3...</td>\n",
              "      <td>[(-0.35362122723998757, 0.09592292335495496, -...</td>\n",
              "      <td>tensor([ 0.3624, -0.8023, -1.2588,  1.9488, -0...</td>\n",
              "      <td>LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...</td>\n",
              "      <td>tensor([ 0.8819, -0.2896, -0.0102,  0.5890,  0...</td>\n",
              "      <td>LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...</td>\n",
              "      <td>[10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...</td>\n",
              "      <td>[10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...</td>\n",
              "      <td>[0, 0, 0, 12, 9, 10, 18, 13, 0, 5, 20, 9, 0, 2...</td>\n",
              "      <td>[0, 0, 0, 12, 9, 10, 18, 13, 10, 5, 0, 0, 0, 0...</td>\n",
              "      <td>[10, 9, 2, 24, 18, 20, 36, 26, 10, 10, 40, 18,...</td>\n",
              "      <td>[10, 9, 2, 24, 18, 20, 36, 26, 20, 10, 20, 9, ...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1H0J</td>\n",
              "      <td>1H0J_A</td>\n",
              "      <td>1H0J_C</td>\n",
              "      <td>----KL-----KTCPAGKNLCYKMFMVATP--PVKRGCIDVCPKSS...</td>\n",
              "      <td>--CNKLVPLFYK----------KMFMVATPKVPVKRG-------SS...</td>\n",
              "      <td>[(0.6666441154110079, 0.2338360596696657, -0.3...</td>\n",
              "      <td>[(0.16223801216970127, -0.4052887381516026, 0....</td>\n",
              "      <td>tensor([ 0.3624, -0.8023, -1.2588,  1.9488, -0...</td>\n",
              "      <td>LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...</td>\n",
              "      <td>tensor([-0.5326,  1.6610, -1.1897, -0.3621,  0...</td>\n",
              "      <td>LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...</td>\n",
              "      <td>[10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...</td>\n",
              "      <td>[10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...</td>\n",
              "      <td>[0, 0, 0, 0, 9, 10, 0, 0, 0, 0, 0, 9, 17, 2, 1...</td>\n",
              "      <td>[0, 0, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 0, ...</td>\n",
              "      <td>[10, 9, 2, 12, 18, 20, 18, 13, 10, 5, 20, 18, ...</td>\n",
              "      <td>[10, 9, 4, 24, 18, 20, 36, 26, 20, 10, 40, 18,...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1H0J</td>\n",
              "      <td>1H0J_B</td>\n",
              "      <td>1H0J_C</td>\n",
              "      <td>----KLV---------------KMFMVATPKVPVKRG----CPKSS...</td>\n",
              "      <td>----KLVP--------------KMFMVATPKVPVKR------PKSS...</td>\n",
              "      <td>[(-0.35362122723998757, 0.09592292335495496, -...</td>\n",
              "      <td>[(0.16223801216970127, -0.4052887381516026, 0....</td>\n",
              "      <td>tensor([ 0.8819, -0.2896, -0.0102,  0.5890,  0...</td>\n",
              "      <td>LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...</td>\n",
              "      <td>tensor([-0.5326,  1.6610, -1.1897, -0.3621,  0...</td>\n",
              "      <td>LKCNKLVPLFYKTCPAGKNLCYKMFMVATPKVPVKRGCIDVCPKSS...</td>\n",
              "      <td>[10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...</td>\n",
              "      <td>[10, 9, 2, 12, 9, 10, 18, 13, 10, 5, 20, 9, 17...</td>\n",
              "      <td>[0, 0, 0, 0, 9, 10, 18, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[0, 0, 0, 0, 9, 10, 18, 13, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[10, 9, 2, 12, 18, 20, 36, 13, 10, 5, 20, 9, 1...</td>\n",
              "      <td>[10, 9, 2, 12, 18, 20, 36, 26, 10, 5, 20, 9, 1...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1H1L</td>\n",
              "      <td>1H1L_B</td>\n",
              "      <td>1H1L_D</td>\n",
              "      <td>SQTIDKINSCYPLFEQD-YQELFR-KR------DAQ-VQ--FA---...</td>\n",
              "      <td>SQTIDKINSCYPLFEQDEYQ-LFR-KR----AHDAQRVQEVFA---...</td>\n",
              "      <td>[(1.0335813771762299, -0.07467590563123697, 0....</td>\n",
              "      <td>[(1.596220592379937, -1.6520011412450177, 0.58...</td>\n",
              "      <td>tensor([ 0.2023,  0.2512, -2.8480,  0.2294, -0...</td>\n",
              "      <td>SQTIDKINSCYPLFEQDEYQELFRNKRQLEEAHDAQRVQEVFAWTT...</td>\n",
              "      <td>tensor([ 1.1608e+00,  1.7323e+00, -1.1385e+00,...</td>\n",
              "      <td>SQTIDKINSCYPLFEQDEYQELFRNKRQLEEAHDAQRVQEVFAWTT...</td>\n",
              "      <td>[16, 14, 17, 8, 3, 9, 8, 12, 16, 2, 20, 13, 10...</td>\n",
              "      <td>[16, 14, 17, 8, 3, 9, 8, 12, 16, 2, 20, 13, 10...</td>\n",
              "      <td>[16, 14, 17, 8, 3, 9, 8, 12, 16, 2, 20, 13, 10...</td>\n",
              "      <td>[16, 14, 17, 8, 3, 9, 8, 12, 16, 2, 20, 13, 10...</td>\n",
              "      <td>[32, 28, 34, 16, 6, 18, 16, 24, 32, 4, 40, 26,...</td>\n",
              "      <td>[32, 28, 34, 16, 6, 18, 16, 24, 32, 4, 40, 26,...</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1H1Y</td>\n",
              "      <td>1H1Y_A</td>\n",
              "      <td>1H1Y_B</td>\n",
              "      <td>------SMLSSDFANLAAEADRM-R-------MDIMDGHFVPNLTI...</td>\n",
              "      <td>-----PSMLSSDFANLAAEADRM---------MDIMDGHFVPNLTI...</td>\n",
              "      <td>[(-0.9165413095431918, -0.872759328495862, 0.2...</td>\n",
              "      <td>[(-0.5081293394188968, -0.7043022970351518, -1...</td>\n",
              "      <td>tensor([ 1.1525e-01,  1.9326e+00, -1.5379e-01,...</td>\n",
              "      <td>AAKIAPSMLSSDFANLAAEADRMVRLGADWLHMDIMDGHFVPNLTI...</td>\n",
              "      <td>tensor([-5.6799e-01,  9.8331e-01,  3.2209e-01,...</td>\n",
              "      <td>AAKIAPSMLSSDFANLAAEADRMVRLGADWLHMDIMDGHFVPNLTI...</td>\n",
              "      <td>[1, 1, 9, 8, 1, 13, 16, 11, 10, 16, 16, 3, 5, ...</td>\n",
              "      <td>[1, 1, 9, 8, 1, 13, 16, 11, 10, 16, 16, 3, 5, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 16, 11, 10, 16, 16, 3, 5, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 13, 16, 11, 10, 16, 16, 3, 5, ...</td>\n",
              "      <td>[1, 1, 9, 8, 1, 13, 32, 22, 20, 32, 32, 6, 10,...</td>\n",
              "      <td>[1, 1, 9, 8, 1, 26, 32, 22, 20, 32, 32, 6, 10,...</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>1JTC</td>\n",
              "      <td>1JTC_B</td>\n",
              "      <td>1JTC_D</td>\n",
              "      <td>HHHHF-----------------------------------------...</td>\n",
              "      <td>HHHHF-----------------------------------------...</td>\n",
              "      <td>[(-1.6365909302872783, -0.7891050628266867, 0....</td>\n",
              "      <td>[(-1.6376207763187678, -0.588986676641465, -1....</td>\n",
              "      <td>tensor([-1.1383, -0.9070, -1.8404, -1.6600,  0...</td>\n",
              "      <td>HHHHFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHI...</td>\n",
              "      <td>tensor([ 0.5820, -1.1304,  1.0858,  0.1613, -0...</td>\n",
              "      <td>HHHHFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHI...</td>\n",
              "      <td>[7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...</td>\n",
              "      <td>[7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...</td>\n",
              "      <td>[7, 7, 7, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[7, 7, 7, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[14, 14, 14, 14, 10, 12, 10, 13, 13, 6, 12, 20...</td>\n",
              "      <td>[14, 14, 14, 14, 10, 12, 10, 13, 13, 6, 12, 20...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>1JTC</td>\n",
              "      <td>1JTC_C</td>\n",
              "      <td>1JTC_D</td>\n",
              "      <td>HH--------------------------ILPDGTVD--------H-...</td>\n",
              "      <td>--------------------SNGGHF-RILPDGTVDGTRD--D---...</td>\n",
              "      <td>[(-2.004807697727987, -1.9555466195303108, -0....</td>\n",
              "      <td>[(-1.6376207763187678, -0.588986676641465, -1....</td>\n",
              "      <td>tensor([ 0.2318, -0.2502, -1.1894, -0.6210,  0...</td>\n",
              "      <td>HHHHFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHI...</td>\n",
              "      <td>tensor([ 0.5820, -1.1304,  1.0858,  0.1613, -0...</td>\n",
              "      <td>HHHHFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHI...</td>\n",
              "      <td>[7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...</td>\n",
              "      <td>[7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...</td>\n",
              "      <td>[7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[14, 14, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9...</td>\n",
              "      <td>[7, 7, 7, 7, 5, 12, 10, 13, 13, 6, 12, 20, 9, ...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>1JTP</td>\n",
              "      <td>1JTP_A</td>\n",
              "      <td>1JTP_L</td>\n",
              "      <td>--------------------SC--------P--MG--------ERE...</td>\n",
              "      <td>KV-----------------------GNWVCAAK-------------...</td>\n",
              "      <td>[(-0.6264680106736783, -0.5317168732427161, -0...</td>\n",
              "      <td>[(-0.12521386043783925, 0.6731528767441878, -0...</td>\n",
              "      <td>tensor([ 0.4172,  0.4715, -0.8095, -0.2510, -0...</td>\n",
              "      <td>DVQLQASGGGSVQAGGSLRLSCAASGYTIGPYCMGWFRQAPGKERE...</td>\n",
              "      <td>tensor([-3.4528e-01,  3.7102e-01, -7.3307e-01,...</td>\n",
              "      <td>KVYGRCELAAAMKRLGLDNYRGYSLGNWVCAAKFESNFNTHATNRN...</td>\n",
              "      <td>[3, 18, 14, 10, 14, 1, 16, 6, 6, 6, 16, 18, 14...</td>\n",
              "      <td>[9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[9, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>[3, 18, 14, 10, 14, 1, 16, 6, 6, 6, 16, 18, 14...</td>\n",
              "      <td>[18, 36, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, ...</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>1JTP</td>\n",
              "      <td>1JTP_A</td>\n",
              "      <td>1JTP_M</td>\n",
              "      <td>DVQLQASGGGS-----------------IG-YCMGWFRQAPGKER-...</td>\n",
              "      <td>-------------------------------A----------TNRN...</td>\n",
              "      <td>[(-0.6264680106736783, -0.5317168732427161, -0...</td>\n",
              "      <td>[(0.4879190177643481, -0.241022180110313, -0.3...</td>\n",
              "      <td>tensor([ 0.4172,  0.4715, -0.8095, -0.2510, -0...</td>\n",
              "      <td>DVQLQASGGGSVQAGGSLRLSCAASGYTIGPYCMGWFRQAPGKERE...</td>\n",
              "      <td>tensor([ 0.9093, -0.0813, -1.3230, -0.4394,  1...</td>\n",
              "      <td>KVYGRCELAAAMKRLGLDNYRGYSLGNWVCAAKFESNFNTHATNRN...</td>\n",
              "      <td>[3, 18, 14, 10, 14, 1, 16, 6, 6, 6, 16, 18, 14...</td>\n",
              "      <td>[9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...</td>\n",
              "      <td>[3, 18, 14, 10, 14, 1, 16, 6, 6, 6, 16, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[6, 36, 28, 20, 28, 2, 32, 12, 12, 12, 32, 18,...</td>\n",
              "      <td>[9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>1JTP</td>\n",
              "      <td>1JTP_L</td>\n",
              "      <td>1JTP_M</td>\n",
              "      <td>KVYGRCELAAA------------SLGN-VCAAKFESNFN-HA-N--...</td>\n",
              "      <td>KVYGRCE------------------GN-VCAAKFESNFNTHATNRN...</td>\n",
              "      <td>[(-0.12521386043783925, 0.6731528767441878, -0...</td>\n",
              "      <td>[(0.4879190177643481, -0.241022180110313, -0.3...</td>\n",
              "      <td>tensor([-3.4528e-01,  3.7102e-01, -7.3307e-01,...</td>\n",
              "      <td>KVYGRCELAAAMKRLGLDNYRGYSLGNWVCAAKFESNFNTHATNRN...</td>\n",
              "      <td>tensor([ 0.9093, -0.0813, -1.3230, -0.4394,  1...</td>\n",
              "      <td>KVYGRCELAAAMKRLGLDNYRGYSLGNWVCAAKFESNFNTHATNRN...</td>\n",
              "      <td>[9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...</td>\n",
              "      <td>[9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 11, 9, 1...</td>\n",
              "      <td>[9, 18, 20, 6, 15, 2, 4, 10, 1, 1, 1, 0, 0, 0,...</td>\n",
              "      <td>[9, 18, 20, 6, 15, 2, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[18, 36, 40, 12, 30, 4, 8, 20, 2, 2, 2, 11, 9,...</td>\n",
              "      <td>[18, 36, 40, 12, 30, 4, 8, 10, 1, 1, 1, 11, 9,...</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>541 rows Ã— 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa1f6f01-6838-43e6-ba4f-b96847224c0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa1f6f01-6838-43e6-ba4f-b96847224c0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa1f6f01-6838-43e6-ba4f-b96847224c0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca5ccfa7-1698-4509-bd04-50acbf59e8b3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca5ccfa7-1698-4509-bd04-50acbf59e8b3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca5ccfa7-1698-4509-bd04-50acbf59e8b3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0bfe7351-9d2d-40d7-8c76-98b0a300064e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pairs_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0bfe7351-9d2d-40d7-8c76-98b0a300064e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pairs_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pairs_df",
              "summary": "{\n  \"name\": \"pairs_df\",\n  \"rows\": 541,\n  \"fields\": [\n    {\n      \"column\": \"pair_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 139,\n        \"samples\": [\n          \"1JT4\",\n          \"1IA1\",\n          \"1HL4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"File Name A\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          \"1IV1_C\",\n          \"1H2S_A\",\n          \"1I5Z_A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"File Name B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          \"1IV1_D\",\n          \"1H2S_B\",\n          \"1I5Z_B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"masked_sequence_A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 442,\n        \"samples\": [\n          \"-------------SG--RA--VR--A-----------SEGLEASKAAVLETAPD--------------------------------------------------------------------------------------------------------------------------------------IWTP-VENSMKQLDPENPRKAAEEFIQVNPSKRYGEAPE-------------------------------\",\n          \"RTLKELERELQPRQHLWYFEYYTGNNVGLFMKMN--IYS----I-R----EN-------ALD-----------------------------------------------------------------------------------------------------------------------------------GVFSAE--------------------------VYLG------------------------------------------EVH-----------------\",\n          \"---A-CV-KGD-------------------------------------EFGDN-AGCTSAG---------------------------------------------SGD-C-IGRT------------------------------GVIGIAQ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"masked_sequence_B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 445,\n        \"samples\": [\n          \"RIGYGEDSHRLEE--------------VGALAHS-G-A--HALTDALLSAYGLGDIGLLFPDTD---R----------A--LV--RGAKLLQASLVLTLD------------------------R-GLTFKTSEGLAPSHVQARAVVLLD\",\n          \"-----------------------------------------------------------------S-------------------------VPYI---------GASYNQGGLFYQYLRDNACVASTPDFELTNK--------------GNVFS-DAF--EDEEFVKKWSSRGNIA------TL--LSKVKGWKS----------AKG--------------------------\",\n          \"------V-KGD------------------------------------HEFGDNTAGCTSAGP-F-P----------------------------------------SGD-CIIGRT-----------------------------CGVIGIA-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coords_A\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          \"[(-0.4417198741155805, 1.4849562199894344, 0.24716828930869522), (-0.5226095987707476, 1.530896224883824, 0.30164608819808214), (-0.6027815519494222, 1.4795862059038065, 0.354181594429471), (-0.6901312198930228, 1.5211184535718425, 0.4044939946065249), (-0.7425909525879828, 1.4627622311384287, 0.47170200079652447), (-0.8212961553581725, 1.4831869089901235, 0.5370847199103334), (-0.860679964198767, 1.4288659572568927, 0.6088793449071712), (-0.9345168039110068, 1.458385514455923, 0.6751279053263525), (-0.9669413501751729, 1.396738994374668, 0.7465949146941305), (-1.0477998673748403, 1.4154874828585944, 0.8093567087754603), (-0.9994283113503384, 1.4438895804791123, 0.8877270474698574), (-1.0411214718979092, 1.3929830885691132, 0.9607619316338506), (-1.0195259126921314, 1.4251100514513382, 1.0451931594658557), (-0.9511503776923355, 1.35141980035723, 1.0909657430687942), (-0.9011560339818502, 1.298712956904072, 1.0203177727736656), (-0.7850330920675458, 1.3082424038652734, 1.0013394674045535), (-0.7522652637928832, 1.3877682772027229, 0.9398413336067406), (-0.6720933106142086, 1.3530959897249983, 0.8799812779542272), (-0.6259062764746841, 1.431814808922411, 0.8230229607305298), (-0.5316909683211541, 1.420671253681137, 0.770113036637358), (-0.5108131805918691, 1.317244161581066, 0.8097779288699658), (-0.5076300201309019, 1.364829315299376, 0.8912138138077091), (-0.578034039738177, 1.3531580708126931, 0.962961636571824), (-0.6157950608927882, 1.4631036771207522, 0.9832504044571756), (-0.6595479135033379, 1.4822246521308493, 1.0650607072567013), (-0.7694917792287058, 1.5193801831163791, 1.0520262854433904), (-0.8808087729960598, 1.5132031148907144, 1.0837581992294765), (-0.9151057665902066, 1.471577745591136, 1.0044518158806226), (-0.8785930436555826, 1.3877372366588756, 0.9489443678713333), (-0.9130772819827275, 1.3398727180459375, 0.8737331798857281), (-1.0034228656542974, 1.2665239129341523, 0.8773837540381094), (-0.9605438217977388, 1.1918403644369218, 0.8168918682438377), (-0.94391024801641, 1.0792252713579726, 0.7958074624021977), (-0.833966382291042, 1.1197021405351915, 0.7780460150838798), (-0.768212273553219, 1.192957824015434, 0.8295050699626434), (-0.8246041456411384, 1.281920022682542, 0.7896295676827827), (-0.7232111227226823, 1.3345337445041572, 0.7661816490886395), (-0.7668703529667329, 1.4147735503501007, 0.7086851061886293), (-0.658268407827851, 1.4564299601935267, 0.6912512744993713), (-0.6087421759498609, 1.3535926384265589, 0.6677565536725051), (-0.7073265278733458, 1.3198515672642608, 0.62467509845113), (-0.7096982944913215, 1.4168843073317345, 0.5734734558523421), (-0.5939810494985129, 1.4079135901597897, 0.5567650587702878), (-0.6050909036563985, 1.2939637536953956, 0.5360784719067923), (-0.6944066412964788, 1.3169027155987425, 0.47970518259213024), (-0.6332400285171087, 1.4058649142658506, 0.44188897855207476), (-0.5405538856830628, 1.3350614337495657, 0.4262102305899232), (-0.6103025487248448, 1.2498861814318598, 0.3916467817241051), (-0.6697839589072324, 1.3314917712070957, 0.34461053783765005), (-0.5691399149207687, 1.3689577076311015, 0.30836220859380975), (-0.5601833751923608, 1.2646925208471462, 0.26640400695778294), (-0.6752140561641765, 1.2406360993652867, 0.25910285865301963), (-0.661950887576813, 1.1469557380333495, 0.3130190307497324), (-0.7686491779302145, 1.1657973481488186, 0.34926735999357267), (-0.7850330920675458, 1.1941063241377938, 0.4351260559236244), (-0.7764822492606339, 1.1501218735058005, 0.5175681888649086), (-0.8883297697714823, 1.1106693422755514, 0.5174979855158243), (-0.8554371116748208, 1.0456394029149123, 0.4477392576424299), (-0.7463670547034439, 1.0136366022080776, 0.47099996730568183), (-0.7537320142013682, 1.0030828172999073, 0.5596901983154653), (-0.8640503693927322, 0.9677276378575359, 0.5800491695499013), (-0.8873623386509922, 0.9195527138061221, 0.6591683439678636), (-0.9283065202665707, 0.8270208525965446, 0.6120852978486858), (-0.8148986269807383, 0.7985566738883317, 0.5975766057046052), (-0.7573832864948304, 0.7456015060843938, 0.6650186230582188), (-0.6526822732934084, 0.796352795275155, 0.6469061589944795), (-0.6962166737154601, 0.9054292663554823, 0.6565006167026618), (-0.7797590320881002, 0.8931682515356958, 0.720128252089364), (-0.7480210498449269, 0.9388288915354572, 0.798592195249207), (-0.6473145909474637, 0.9853276262191026, 0.7659944401577483), (-0.6069321435308795, 1.0928831106508994, 0.7860959991122083), (-0.6242210738777015, 1.1702051053751723, 0.7204792688347853), (-0.5064441368219141, 1.1838008635804036, 0.7099487664721461), (-0.5061008548114176, 1.072365311167662, 0.6795741174350223), (-0.5758183103976999, 1.1043060307868016, 0.6120618967323245), (-0.5122487235448544, 1.201214608678885, 0.5962661431883656), (-0.4121352063018851, 1.1383885479314229, 0.5907902819597931), (-0.4632842258658585, 1.0611596748386927, 0.5354934439977566), (-0.5023559601514562, 1.1483836030503374, 0.48368337237357173), (-0.39197519004909265, 1.1926163780331107, 0.483355756744512), (-0.35115583825551294, 1.0861162720921311, 0.4597206292194772), (-0.43114054670118945, 1.0779215685163752, 0.3943379101056685), (-0.40826548181992495, 1.1822798769318732, 0.3566153105310587), (-0.2908006193191343, 1.170919037883666, 0.36564814144656704), (-0.29623071657607847, 1.0656605536965889, 0.32350273087964876), (-0.34525762916607367, 1.1293557496717828, 0.2583306218130927), (-0.24807761274007417, 1.1971172568910071, 0.26141956917280035), (-0.29073820440813497, 1.286669225891219, 0.3081984007792797), (-0.2237982123613242, 1.3553929899697177, 0.35958725230895916), (-0.28493361768519476, 1.4150839557885764, 0.419915330288701), (-0.25163526266703756, 1.5275438461482873, 0.4201025392195924), (-0.33005959833773013, 1.5840065954069997, 0.47006392265122504), (-0.4284567055282171, 1.5749117160596648, 0.5183170245884741), (-0.4978620865595025, 1.6650224148491324, 0.5436136313751695), (-0.5918901499800344, 1.6428284259981265, 0.5943706527630906), (-0.6715315764152144, 1.6999119861337901, 0.6436066015875193), (-0.7194662280627209, 1.655803373326407, 0.7178349426859448), (-0.8218578895571668, 1.7006879997299793, 0.7456354689233123), (-0.8716649885346538, 1.681008294930626, 0.8248014455739977), (-0.9204734489361512, 1.7477765047467282, 0.8870250139790148), (-0.8642064066702306, 1.695069661293571, 0.9556604882670608), (-0.7857508635440384, 1.6706097127416935, 0.984046042413464), (-0.7004608876634166, 1.74864563997446, 0.9643657035535093), (-0.6159510981702866, 1.7030160405185464, 0.9111047627149164), (-0.5381509116095877, 1.792474887887215, 0.9181484987397039), (-0.4817278320661686, 1.7506632753245515, 0.9898261181547349), (-0.4658744446723318, 1.6511472917492727, 0.9429068798500866), (-0.42702116257523187, 1.6981116345906317, 0.8668532516754701), (-0.3122401412474136, 1.6660467527961018, 0.8742948066784022), (-0.3405140959301225, 1.5541766327694941, 0.8936475299092969), (-0.422246421883781, 1.5469441860530124, 0.8288264375881619), (-0.3493458058365316, 1.592046096263518, 0.7682409473284444), (-0.2616528558824345, 1.521708223904946, 0.7963924903112333), (-0.33520882849517714, 1.428741795081503, 0.7895359632173373), (-0.36360761299988476, 1.4549710546326913, 0.7054791532471147), (-0.25082386882404595, 1.4758613406420995, 0.6819376301875257), (-0.2221442172198412, 1.3701682888411564, 0.7145821875117074), (-0.3122401412474136, 1.3119983096708279, 0.6769063901698206), (-0.30490638920498914, 1.3663503019479062, 0.5976936112864122), (-0.1863492657617098, 1.3711305457004306, 0.5961959398392813), (-0.18940759640067825, 1.4870669769710685, 0.576468798746604), (-0.1268054406683228, 1.5752842025858351, 0.6130213425031427), (-0.19040623497666798, 1.6473293048560231, 0.6650186230582188), (-0.1928404165056429, 1.7336530572960882, 0.6048543528930069), (-0.25182250740003564, 1.6616700361135956, 0.5495809160473318), (-0.3338044929976916, 1.6354718171062548, 0.6109386431469762), (-0.4193441285223109, 1.716953244706101, 0.6094175705834838), (-0.4927440638575552, 1.7056544867455887, 0.6781934515696986), (-0.5710747771617487, 1.788253373923947, 0.7024604092364917), (-0.6525886509269095, 1.7850872384514958, 0.7677261227684934), (-0.7613466333432897, 1.8322067840120924, 0.7658774345759409), (-0.8634574277382384, 1.8274886213472632, 0.8109947869207595), (-0.9675967067406661, 1.8179281338422149, 0.7685919640738658), (-1.0077607019687527, 1.9162335362074385, 0.8073208116520166), (-1.0995730360488074, 1.85145192119758, 0.8353787501693597), (-1.126224203045533, 1.813458295528166, 0.7539428652316167), (-1.090772533597898, 1.7016502565892537, 0.7723595438080545), (-1.074170167272069, 1.6933003502942598, 0.8601371312797427), (-1.087558165681431, 1.5755635674804631, 0.864559942272051), (-1.0110998997072183, 1.5447403074398358, 0.8009791091180717), (-0.8965061231123981, 1.5449265507029213, 0.7818369959344298), (-0.8774071603465947, 1.5718697427626034, 0.6958144921898481), (-0.77782416984712, 1.5574979709611831, 0.6483336270925261), (-0.7524525085258813, 1.5921702584389084, 0.5653298673585678), (-0.647283383491964, 1.574321945726561, 0.5273498555039823), (-0.5868033347335867, 1.5957709615252254, 0.45220887086746125), (-0.49059074942807734, 1.5321688871815737, 0.43126487172398986), (-0.40942015767341305, 1.556039065400348, 0.36805845643179325), (-0.33804870694564787, 1.4712673401526601, 0.3348288711985763), (-0.24358373914812048, 1.4668595829263067, 0.2817083370581518)]\",\n          \"[(-0.5751941612877062, -0.5813817433988127, 0.20387622404006736), (-0.5053206684239258, -0.5514276185859168, 0.13566196984652676), (-0.5554398419564097, -0.544288293500978, 0.05586416305408308), (-0.44967777526799857, -0.4984414102381314, 0.03538818623784019), (-0.40586250774644966, -0.6060589757576231, 0.019873246090218333), (-0.5039475403819398, -0.6280667213455435, -0.026952387748983942), (-0.48344424211865095, -0.5341380356628258, -0.07848164597683174), (-0.3705356681208134, -0.5672893364920202, -0.08976098406303655), (-0.40283538456298085, -0.6765210102915853, -0.11295149037720413), (-0.48026108165768366, -0.6304878837656531, -0.17110326453533395), (-0.39231847205958914, -0.5658614714750324, -0.2059007245647662), (-0.32356844759379694, -0.6618698735955367, -0.2100427221607376), (-0.4087335936524201, -0.7234543125890965, -0.25129889030592184), (-0.42801980115122157, -0.6372547223244214, -0.3101526979548943), (-0.3120216890589158, -0.6268561401354886, -0.32800774973865815), (-0.30166081383302257, -0.7449964500193035, -0.3348876779489158), (-0.3921000198710914, -0.7519184912973094, -0.39151837954355323), (-0.34310431473659586, -0.6676744552950306, -0.4402395038080306), (-0.23659326911619247, -0.7184257444857917, -0.4376653810082744), (-0.2803773291822416, -0.8210457824458264, -0.46640195190009864), (-0.3459441931870666, -0.7685872633434494, -0.5295849660759339), (-0.253632539819017, -0.7089273380684383, -0.5627677490764281), (-0.181855392169756, -0.8033837129965645, -0.5592341805058536), (-0.261590440971435, -0.8690655037780023, -0.6033686859634926), (-0.2847463729521967, -0.7833625622148881, -0.662830922637862), (-0.16987172925787936, -0.7791720887954674, -0.6826282670796237), (-0.1535190225760478, -0.896132858013075, -0.6901868276643626), (-0.14627889290012228, -0.8899868303312579, -0.7788536575577846), (-0.11045273398649114, -0.7776200616030895, -0.7838614964591285), (-0.033120659258287395, -0.7495283694210473, -0.8476997418930836), (0.07972549982855075, -0.7170599605564991, -0.8355545625015064), (0.045085224223907414, -0.6049104756352635, -0.8415218471736686), (-0.046258998023652104, -0.608821584160056, -0.7845167277172485), (0.009727177142771484, -0.6784144834662864, -0.7256863211846374), (0.05919099410976224, -0.5935496365870564, -0.6749995031458006), (-0.04788178570963539, -0.5438226853432645, -0.6660368755793766), (-0.10034151840459529, -0.639613803656836, -0.6326434825316296), (-0.007031226460555944, -0.6636702251386952, -0.5807866086747219), (-0.009090918523534816, -0.5542212675321972, -0.5484228647468773), (-0.12499540824934144, -0.5597154437932155, -0.5290467403996213), (-0.1072383660700243, -0.6622423601217075, -0.4866439175527274), (-0.020700091969415284, -0.6114910709309461, -0.43904604687359816), (-0.0872655945502299, -0.5172519798097529, -0.4190146912682223), (-0.1792027584522834, -0.5781535268386664, -0.38688495850399196), (-0.11263725587146865, -0.6675192525757928, -0.35594868267419416), (-0.04669590240064759, -0.6008441643912331, -0.3030855608137453), (-0.1437198815491487, -0.5423948203262767, -0.2761742769981118), (-0.19318369851613934, -0.6476533045133541, -0.2567981526508557), (-0.10062238550409242, -0.6759312399584816, -0.20473066874669515), (-0.10599006785003717, -0.5726283100338005, -0.16150880682715155), (-0.22139523828784888, -0.5873725683613918, -0.14517482760688008), (-0.20576030308250992, -0.6981562693533349, -0.1159234321551045), (-0.11969014081439612, -0.6615284276132135, -0.06118822098574209), (-0.18903310693468212, -0.576477337470898, -0.028075641334332168), (-0.2819689094127253, -0.6503538318280918, -0.022599780105759738), (-0.2128756029364366, -0.7209089879935966, 0.027361603325872886), (-0.1942447520031285, -0.6306120459410435, 0.08336047477875205), (-0.0829589656912742, -0.6109944222293853, 0.05766604901391242), (-0.03524276623226548, -0.5047736811830337, 0.04390619259339716), (-0.11301174533746482, -0.44607601276729697, 0.09438240058498117), (-0.057961793836031617, -0.3514644351199329, 0.12917986061441325), (-0.11504022994494396, -0.29202179365185477, 0.1943753707973307), (-0.05836749075752749, -0.18899822862180185, 0.18063891549317695), (-0.08383277444526527, -0.10223990856787053, 0.2390949041640052), (-0.1978960242965908, -0.12493054612043723, 0.2584242262785385), (-0.21512253973241355, -0.15870265782658297, 0.17420360849378622), (-0.20778878768998896, -0.2567597358410262, 0.1259271054401759), (-0.1444688604811409, -0.26396114201366017, 0.05052870852367918), (-0.12493299333834211, -0.3591314494502803, 0.0002865116957095016), (-0.014146526314482733, -0.37421715376019465, -0.02744381119257379), (-0.042326858630692556, -0.4545500812376809, -0.09022900639026486), (-0.11407279882445386, -0.37530357279485926, -0.12942587629564414), (-0.024538608995875687, -0.29934736199987905, -0.14386436509064057), (0.053542444664320364, -0.3845846954052798, -0.1649019686995575), (-0.0262238115928584, -0.42450283479324247, -0.22415359532667412), (-0.03596053770875808, -0.31623341785295184, -0.2590914620542749), (0.08075534586004018, -0.2991921592806412, -0.26360787751202897), (0.09167795528492777, -0.39957727808365145, -0.3107143247475684), (-0.008997296157035775, -0.40103618364448684, -0.3589908278011788), (-0.0266919234253536, -0.2885762932847755, -0.38424063235515143), (0.0758245678910909, -0.2876450769693487, -0.4294047869326929), (0.03825079146947775, -0.38415012779141394, -0.4729542644812964), (-0.06142582139649597, -0.32666304058573215, -0.49403867032293625), (0.004796399173822212, -0.23555904439314243, -0.5228220434474834), (0.07229812541962723, -0.31350184999436653, -0.5663715209960869), (-0.023415140597887324, -0.3593487332572132, -0.6069958589995127), (-0.05930371442251778, -0.2514828433869409, -0.6307245909899931), (0.05113947059084505, -0.22525358383575236, -0.657986891551048), (0.054197801229813644, -0.3222552833593786, -0.7084162973099091), (-0.04678952476714663, -0.28960063123174506, -0.7488300252660822), (-0.0034423690780929425, -0.18024479525678982, -0.7604135778649853), (0.09642148852087885, -0.22525358383575236, -0.7945558066362977), (0.17269250976209366, -0.17481270008346675, -0.73874414411431), (0.29056306918438013, -0.18788076904328965, -0.7408736457031992), (0.3603429396816616, -0.21473083947142943, -0.6705298899207693), (0.3770701358294894, -0.1007499624631877, -0.6501709186863335), (0.26200824740217393, -0.07200641886034671, -0.6504049298499478), (0.2357003624159449, -0.16919436164705828, -0.6032984826144083), (0.31733906600310435, -0.13840214215027835, -0.543110811332835), (0.2693732069000982, -0.032150360560079215, -0.5331653368792313), (0.15883639952023623, -0.06955421589638942, -0.5171823744043811), (0.19272769619288727, -0.15870265782658297, -0.46558291282744896), (0.2590747465852043, -0.08408119041704769, -0.4173532120065614), (0.16810501380364082, -0.0102357366037016, -0.4053250381967913), (0.09492353065689434, -0.09848400276231577, -0.3846384513332956), (0.16988383876712246, -0.142313250675071, -0.32484859902986635), (0.17999505434901852, -0.03764453682109739, -0.2850198989827288), (0.0626862291257262, -0.03398175264708531, -0.2759870680672204), (0.05510281743930432, -0.1429030210081747, -0.24114280580506542), (0.14835069447234425, -0.13157322250381512, -0.18804567278100237), (0.10803066196675933, -0.02737011680755492, -0.1579986393729385), (0.0031424040323392156, -0.07318595952655402, -0.13553356766597485), (0.05391693413031653, -0.16475556387685714, -0.09495603189527184), (0.13090572684802382, -0.09916689472696205, -0.04859842038329796), (0.04605265534439742, -0.021317210757280634, -0.028122443567055063), (-0.02535000283886733, -0.10760992265349854, 0.0010587485356362396), (0.05993997304175445, -0.1471245349714429, 0.05492811839962628), (0.0876834009809689, -0.03826534769804858, 0.08450712948046164), (0.03506763100851062, 0.01338611726429183, 0.15501469307742144), (0.023115175552133597, 0.1303158459380518, 0.15693358461905793), (0.008572501289283403, 0.21490132792265387, 0.09648850105750892), (0.10622062954777796, 0.17616272920089848, 0.05497492063234902), (0.03949908968946498, 0.09483650432029035, 0.015684446261524022), (-0.013928074125984938, 0.18302268939120933, -0.02814584468341643), (0.08989913032144602, 0.21819162557049532, -0.06240507903653594), (0.10484750150579208, 0.10771833001702788, -0.09238190909551552), (-0.005346023863573341, 0.1094566004724913, -0.12462864744155291), (0.021336350588651954, 0.20971755710011133, -0.16728888256842242), (0.11539562146468352, 0.15840753812009395, -0.20501148214303222), (0.04630231498839493, 0.07161817752231515, -0.2352457244819874), (-0.03942456526922244, 0.1457740367741369, -0.26201660159945245), (0.03644075905049639, 0.2099969219947393, -0.3110653414929897), (0.08612302820598494, 0.1135849928042168, -0.3459564059878676), (-0.023758422608383765, 0.07528096169632723, -0.3663855805713877), (-0.04844351990862962, 0.1747969452716059, -0.4106370916108337), (0.05201327934483613, 0.15909043008474036, -0.4559182517701823), (0.020244089646163196, 0.04815152637355949, -0.47403071583392176), (-0.08835785549271867, 0.08369294907901612, -0.5011292085804466), (-0.0357420855202604, 0.16328090350416094, -0.5547879683971837), (0.03019926795056067, 0.07928519185266256, -0.5932360025789976), (-0.06326706127097693, 0.007115927407084688, -0.6038835105234439), (-0.1327660646687614, 0.08959065241005262, -0.6403190486981755), (-0.046883147133645664, 0.14561883405489912, -0.6842663452249231), (0.05466591306230884, 0.09604708553034515, -0.7153664288692508), (0.014595540200721324, -0.014860777636988124, -0.7069420269791395), (-0.08807698839322155, 0.010157900704145574, -0.747379156051674), (-0.029188519865327844, 0.0576188922470654, -0.8156402124779376), (0.03825079146947775, -0.03919656401347543, -0.8188695665358136), (-0.057774549103033535, -0.10888258495124853, -0.8195481989102948), (-0.10230758810107501, -0.04397680776599973, -0.8860775727258131), (-0.016299840743960535, -0.08839582601185866, -0.9375600287209381), (-0.06036476790950682, -0.19741021600449074, -0.9270061252419376), (-0.15610924138252108, -0.2453988967928191, -0.9649159337474387), (-0.26446152687740554, -0.20079363528387478, -0.9496818069961538), (-0.2895835285546469, -0.2950637669489157, -0.9003522537062796), (-0.19302766123864099, -0.2814680087436842, -0.8497356390165273), (-0.2094739902869717, -0.16540741529765593, -0.8405858025192117), (-0.32266343138430625, -0.18533544444778968, -0.8211394748228714), (-0.2951384556335897, -0.2656062908375809, -0.75933712651236), (-0.21000451703046621, -0.19725501328525288, -0.7252416999737703), (-0.285588974250688, -0.107858247004279, -0.7161620668255392), (-0.3688192580683311, -0.1733227539787838, -0.6775970270619183), (-0.29208012499462116, -0.21997669138166706, -0.618579411598416), (-0.23824726425767545, -0.11627023438696789, -0.6063640288577544), (-0.341918431427608, -0.06387379637228588, -0.5864730799505471), (-0.3718775887072996, -0.1489869676022965, -0.5298423783559095), (-0.26471118652140296, -0.14076122348269296, -0.49111353077775866), (-0.2575022643009771, -0.023831494808933013, -0.4849356360583437), (-0.36697801819385, -0.009987412252921143, -0.45467799260302705), (-0.366884395827351, -0.09739758372765116, -0.3948881402995978), (-0.25469359330600605, -0.08606778522329155, -0.3686086866257226), (-0.28203132432372463, 0.026516267311809928, -0.34857733102034666), (-0.3579590635544429, -0.012470655760725922, -0.286704779360751), (-0.27725658363227385, -0.0727203513688406, -0.23873249081983908), (-0.22445356892681748, 0.02452967250556606, -0.20501148214303222), (-0.32959148650523495, 0.06233705491189461, -0.1751282565494983), (-0.347847847972547, -0.03978633434657903, -0.13366147835706127), (-0.23843450899067353, -0.03298845524396338, -0.10040849200748282), (-0.25653483318048714, 0.07701923215179064, -0.07012744743580465), (-0.3638260651883825, 0.05513564873926062, -0.03701486778439473), (-0.3384544038671437, -0.05431330886723729, -0.010782216343242515), (-0.2717640714643303, -0.0971182188330231, 0.05635558649767293), (-0.16934120251438484, -0.05785193086585919, 0.020224262835639654), (-0.20844414425548224, 0.0534904999153399, 0.02151132423551777), (-0.2932348008481093, 0.10296912680835119, 0.07210453780890877), (-0.3433227669250936, -0.001854789764860309, 0.08607500427667682), (-0.45501425015844366, 0.03272437608132198, 0.06826675472563579), (-0.4736138936362521, -0.07023710786103582, 0.02677657541683741), (-0.47052435554178396, -0.1666800775954059, 0.07849304257557663), (-0.3990280749920201, -0.25828072248955664, 0.05703421887215404), (-0.4928376862240542, -0.31998932365850663, 0.028227444631245418), (-0.5328144367191426, -0.23509343623542903, -0.02594613974544288), (-0.4221215920617823, -0.2113784607358929, -0.053138236957413425), (-0.40121259687699756, -0.32563870263876266, -0.07176552558110409), (-0.5061320622669173, -0.33817908235317706, -0.1135833205189625), (-0.48615929074712294, -0.24598866712592268, -0.16654004684485696), (-0.37568489827826035, -0.2824302656029586, -0.18619698458845013), (-0.4116983019248896, -0.39271731789334063, -0.20344360734681705), (-0.4887183020980966, -0.3475843671389879, -0.26166558485403113), (-0.4088584234744188, -0.2757255081318855, -0.29917757438138814), (-0.32356844759379694, -0.3586658412925669, -0.30200910946112), (-0.3957200847090541, -0.43564639003451666, -0.3430546675590515), (-0.4254607898002479, -0.3556859490832011, -0.4041081801459974), (-0.3166091850173686, -0.3114842146442751, -0.41831265777737964), (-0.2710775074433374, -0.42043652354921207, -0.42556700384942003), (-0.3544950359939786, -0.4999003157989666, -0.4470960309019268), (-0.4264906358317373, -0.42459595642478515, -0.4890776336543151), (-0.3315887636572144, -0.37968028947736526, -0.5299359828213552), (-0.30134873927802575, -0.4884773956630644, -0.5571748822660486), (-0.40907687566291656, -0.5188971286336737, -0.5859816565069572), (-0.41466301019735907, -0.421429820952334, -0.636340858916734), (-0.3107733908389287, -0.45352574329071144, -0.6733614250005012), (-0.34900252382603514, -0.5648060929842154, -0.6837749217813333), (-0.4479301577600166, -0.524515467070082, -0.7234164128975795), (-0.38155189991219995, -0.4650417850581563, -0.7820830116156605), (-0.3070284961789673, -0.5542833486198925, -0.8013421303811096), (-0.37062929048731247, -0.601558096899727, -0.8678481030802665), (-0.3866699226141473, -0.4969825046772959, -0.9082618310364398), (-0.2705469806998429, -0.47292608319543666, -0.9032071899023729), (-0.24333407950412309, -0.5762910942078128, -0.9415148173860182), (-0.3206037393213275, -0.5551214433037766, -1.0072017510125255), (-0.26583465491939146, -0.45212891881757117, -1.0228102956255927), (-0.16703185080740868, -0.5093676816724725, -1.0465624287324344), (-0.22794880394278144, -0.5775016754178676, -1.1023506901380609), (-0.24779674564057705, -0.6672088471373171, -1.0464454231506275)]\",\n          \"[(0.12725445455456139, 1.1623518477817396, 0.5722331966851867), (0.12194918711961607, 1.0874199749337288, 0.640868670973233), (0.056725605125287605, 1.0532443361575647, 0.7106273988466275), (0.06537007029869864, 0.9981784113719927, 0.7897933754973128), (0.05135792277934285, 0.8913678999925373, 0.7531004250426055), (0.14001830385393005, 0.9074158611617261, 0.6954634754444268), (0.20839383885372603, 0.9552493392308166, 0.7589039019002376), (0.18592447089395742, 0.8649523971782634, 0.8137093164186843), (0.22437205606956154, 0.7942730788373684, 0.7485372073521284), (0.32080309356356856, 0.8597686263557208, 0.7307289578010875), (0.3531964323722352, 0.8624070725827635, 0.8168450660111146), (0.3727947144260334, 0.7464085602244303, 0.8081164496083051), (0.44541446337378565, 0.7632946160775033, 0.7385683317821633), (0.5583854522826227, 0.794800768082777, 0.7275464059759345), (0.578732713268413, 0.882210939557507, 0.6694882362832502), (0.6629616356620459, 0.8732091818417145, 0.6071008600637032), (0.7010971462826532, 0.9513382307060241, 0.5474280133420811), (0.7245339453629119, 0.9251089711548356, 0.46248196095012484), (0.7832039617023078, 0.9991096276874195, 0.407887156478931), (0.7374850393952787, 1.0161819268035777, 0.3269426949847775), (0.7613587428525328, 0.9243019170147989, 0.27333073740076336), (0.7834224138908057, 0.8496804496052638, 0.3404685402416786), (0.7274986536353815, 0.7454773439090037, 0.3401643257289802), (0.6538802661116393, 0.7217313278656199, 0.40767654643167817), (0.617305128266016, 0.6154174651877254, 0.38057805368515324), (0.671980590301453, 0.5383437948142331, 0.32631086484301913), (0.6110636371660801, 0.459128326915259, 0.2790172086765884), (0.6290079240783955, 0.3506726667118831, 0.31142775483715585), (0.6485437912211943, 0.38233402143639456, 0.3958355815527994), (0.5887190990283102, 0.3230155421437066, 0.4580591499578164), (0.4914766676913114, 0.38587264343501654, 0.4775288787705182), (0.4857657033348702, 0.3998408881664186, 0.5660084997330489), (0.47187838563751316, 0.5165533330332458, 0.5752519406958101), (0.3889289689193672, 0.5982520444400247, 0.557771306773829), (0.41579858810459064, 0.7099980022912421, 0.5350020205541668), (0.3575654761421902, 0.812524918619734, 0.537459137772116), (0.39389095434381627, 0.911233848054976, 0.4964603819069073), (0.39573219421829725, 1.0010962224936635, 0.554050529272363), (0.44797347472475935, 1.0717134597468632, 0.49435428143437954), (0.48464223493688174, 1.0664055267489303, 0.41006346030054297), (0.4566803548091698, 1.001189344125206, 0.339041072143632), (0.4938796417647868, 0.8993142792175127, 0.3040564031833083), (0.4874196984763533, 0.8376987996801054, 0.22833039063775176), (0.4573045039191633, 0.7234695983210833, 0.22442240420539453), (0.5105444230016152, 0.6653927407822977, 0.15803343708804476), (0.5220911815364963, 0.5583959861397572, 0.12204252012418003), (0.603417810568659, 0.5188503332779651, 0.06440557052600143), (0.6169306388000199, 0.4502507313748567, -0.006967834376330893), (0.7035001203561285, 0.37097318238818744, -0.022552977873036843), (0.7721877299109213, 0.4504369746379421, -0.06345812927279991), (0.7597671626220491, 0.5355811864118003, -0.0027556334312752173), (0.6714188561024589, 0.5980968417207868, -0.038512539231525644), (0.6100025836790911, 0.6534731719448345, 0.025325706202429396), (0.49322428519929357, 0.6717870928148952, 0.030263341754689078), (0.44463427698629376, 0.7444840465058816, 0.09021700187264822), (0.3477039202042917, 0.6972713793137422, 0.12749498023639108), (0.32164569486205996, 0.7928762543642282, 0.17481203751918323), (0.35784634324168735, 0.8867428589592508, 0.22067822558756733), (0.32782477105099633, 0.8908091702032812, 0.3068879382630402), (0.32745028158500017, 0.9834031125005539, 0.36162314943240265), (0.31649646470461296, 1.023290211344669, 0.44483751921361386), (0.23176822302298544, 0.9630405157365544, 0.4868425230823635), (0.24780885514982015, 0.8657594513183001, 0.437723579839742), (0.27221308535056904, 0.7598491157104239, 0.47195941307650013), (0.3575654761421902, 0.697147217138352, 0.43051603600042454), (0.3935164648778201, 0.5849977322171164, 0.43662372737075533), (0.2850081421054372, 0.5471903498107877, 0.4582229577723463), (0.27221308535056904, 0.4596560161606674, 0.39927554565792817), (0.32429832857953267, 0.3760017504914922, 0.44851149448235683), (0.26494174821914374, 0.399251117833315, 0.5240034958642992), (0.17834105920753543, 0.31876298763659106, 0.5166087430940904), (0.24637331219683498, 0.2237478829192087, 0.5037147279789477), (0.35428869331472385, 0.2009641237350993, 0.536850708746719), (0.44603861248377935, 0.17001670151908163, 0.4860468851260752), (0.42697085717347555, 0.24358279043779965, 0.418136845445233), (0.5038972349801836, 0.30873689197382903, 0.37187283839870483), (0.49728125441425164, 0.4234006609467169, 0.35207549395694304), (0.4406709301378345, 0.4335198782410216, 0.273705155262546), (0.5008389043412151, 0.5271691990291114, 0.24290928613091667), (0.5856607683893417, 0.6064467480157805, 0.260343117820175), (0.5559824782091473, 0.7072043533449616, 0.30110786252176935), (0.6280717004134051, 0.7993016469406732, 0.2908815746718287), (0.62470129521944, 0.9079435504071345, 0.32525781460675535), (0.5958968137932364, 0.9897974645331512, 0.26457871988159204), (0.6190839532294975, 1.0772697170955765, 0.3217710482689037), (0.6655830619240188, 1.0760280953416739, 0.40362815330115237), (0.595740776515738, 1.0062489527723584, 0.45321511887100235), (0.5676540665660271, 0.9887110454984868, 0.5386759958229098), (0.516099350080558, 0.8830490342413911, 0.5475918211566111), (0.4710357843390218, 0.8290074474027884, 0.6186844126626063), (0.48704520901035714, 0.7126364485182848, 0.6259387587346467), (0.44244975510131623, 0.6267162231482376, 0.6761809555626164), (0.4499707518767388, 0.509041521422136, 0.6760873510971706), (0.35806479543018505, 0.44959887995405795, 0.6419919245585811), (0.3486089364137825, 0.394160468642315, 0.720245257671171), (0.33578267220341446, 0.4946076685330206, 0.7659710390413867), (0.26107202373718374, 0.5389646056911842, 0.7055025543634762), (0.1897005730094186, 0.4443530280438203, 0.7092935352140265), (0.18395840119747758, 0.45993538105529547, 0.797211529383883), (0.1514090251113127, 0.572240068695769, 0.7833112662651993), (0.06565093739819564, 0.5375988217618917, 0.7272889936959586), (0.015999875698206916, 0.475300450259838, 0.793139735136996), (0.020524956745660315, 0.5684531223463667, 0.8478515451899968), (-0.029157312409828124, 0.6403740624411641, 0.787195851581195), (-0.059709411344013655, 0.5954583954937441, 0.7067896157633545), (-0.07550038382685108, 0.704845272012547, 0.6751981086754367), (0.04018565371045786, 0.7046279882056141, 0.655447566466398), (0.02136755804415167, 0.6112269917683049, 0.6025610434895876), (-0.07131858478989413, 0.666292916553877, 0.5651894606603993), (-7.19638841276269e-05, 0.7558759260979362, 0.5428179934188813), (0.08047447876054306, 0.6828375264246267, 0.5077631211094735), (-0.001351469559614465, 0.6209116414487437, 0.4630903899755217), (-0.04632141293465143, 0.720241381760937, 0.42805891878247526), (0.0583796002667706, 0.7433355463835218, 0.3905001270223955), (0.06958307679115519, 0.6332036968123775, 0.3594234444944291), (-0.03773936267223983, 0.6421744139843226, 0.3212094214762296), (-0.007624168115049898, 0.7438632356289303, 0.28177854040723604), (0.09348798770390913, 0.6955951899459739, 0.2532993817953874), (0.03722094543798842, 0.6047395181041647, 0.21595120008256027), (-0.036116574986256554, 0.6783056070228829, 0.17319736049024514), (0.05603904110429461, 0.7422491273488572, 0.14410977285299964), (0.12363438971659867, 0.6507105635424016, 0.12136388774969892), (0.03307035385653118, 0.6004559230532014, 0.07772080573564973), (0.017529041017691156, 0.6998167039092422, 0.030754765198278924), (0.133027833822002, 0.6931429869820168, 0.011355239734661352), (0.11798584027115691, 0.5835388266562809, -0.020283069585979193), (0.03154118853704683, 0.6236742498511765, -0.07316959256278938), (0.09667114816487636, 0.7131951783075406, -0.10417607174167146), (0.1889515940774263, 0.6429814681243591, -0.12338838827439769), (0.11845395210365199, 0.564759297628507, -0.16331069278698096), (0.045802995700400015, 0.6370216837056276, -0.20838124289907672), (0.10818669924425779, 0.734644194106205, -0.2267979214755147), (0.198781942559825, 0.7440184383481682, -0.2832648152556222), (0.2965549006403184, 0.7950490924335574, -0.25040964788418785), (0.26129047592568144, 0.9005869415152629, -0.28048008240861316), (0.1575881013002491, 0.8962102248327567, -0.2373752260708767), (0.21089043529370027, 0.8557023151116904, -0.16405952851054642), (0.28525780174943466, 0.9471477572866034, -0.16377871511420938), (0.19244682909339014, 1.0178891567151935, -0.17852141842190422), (0.13262213690050614, 0.9725699626977553, -0.10946472403935247), (0.2287723072950162, 0.9786228687480295, -0.057397240135192), (0.24537467362084536, 1.0935970431593933, -0.07361421377365632), (0.14176592136191196, 1.104895801119905, -0.030790170832256932), (0.14909967340433655, 1.0317953203589005, 0.03899195815749885), (0.24646693456333402, 1.0942178540363445, 0.058602093668369215), (0.18505066213996646, 1.1943546484885743, 0.06829015584199731), (0.129719843539036, 1.136464034212874, 0.13395368835214305), (0.22399756660356537, 1.1181501133428136, 0.1863955901180863), (0.23729194264642856, 1.1908781075776476, 0.25659893920234766), (0.3394027370413772, 1.2315722605617991, 0.2230183372237094), (0.2776743900630127, 1.2671136832672556, 0.15185554236862972), (0.2803270237804854, 1.382615546924028, 0.13381328165397452), (0.21675743692763993, 1.4585717577190083, 0.08527936632038854), (0.22340462494907154, 1.5238810619742753, 0.011168030803769926), (0.14741447080735384, 1.5912700826673287, -0.03554059745362535), (0.14117297970741813, 1.5082366278751047, -0.09888741944399046), (0.111557104438223, 1.4190261048572164, -0.04527546185997619), (0.2009040495338031, 1.388264925904284, 0.008406699073122264), (0.31883702386708895, 1.3743587622605766, 0.007751467815002522), (0.3785368862379742, 1.277419143824646, 0.031152584176422977), (0.49319307774379373, 1.2489860056602808, 0.038009111270319154), (0.5058633046766632, 1.1427342240700813, 0.0010119463029135078), (0.5957719839712375, 1.0953663541587042, -0.044760637300024976), (0.5941491962852543, 1.0223900355730897, -0.11472997522067209), (0.6357175270108263, 0.9368112561853656, -0.06207746340747599), (0.5508332480517003, 0.9497551629697983, -0.0007197363078315606), (0.4669164002130643, 0.9481410546897253, -0.06355173373824553), (0.5152879562375664, 0.8524430580076966, -0.1000106730293386), (0.5155376158815637, 0.7951732546089477, -0.02210835666216989), (0.40063176473174666, 0.8194159193538924, -0.013754158121142805), (0.3642438716191214, 0.7884995376817222, -0.09565806538611439), (0.4438540905988018, 0.7048142314686995, -0.11423855177708225), (0.5115118541221052, 0.7551309530455949, -0.17664932911299064), (0.6231721298999554, 0.7907965379264416, -0.19209406591152814), (0.6552846016091249, 0.9034426715492384, -0.18039350773081791), (0.6782220814013887, 0.9108924020726528, -0.2674690617116634), (0.5687463275085158, 0.8789206419096657, -0.2915488104475651), (0.5198130372850197, 0.9469925545673655, -0.22890402194804252), (0.5765481913834355, 1.0380655102161076, -0.2652693567736899), (0.5338875997153748, 1.0149403050496753, -0.3466818405950716), (0.4233507923355128, 1.0031448983876021, -0.3154881524852982), (0.4272829317284725, 1.1035610577344601, -0.2684753097152045), (0.458115897762155, 1.1596202799231543, -0.343475887653557), (0.36405662688612334, 1.114580450800344, -0.38569150156955956), (0.29184257485986687, 1.1490044139272886, -0.32037898580483504), (0.3289482394489848, 1.260967655585439, -0.3227424985573385), (0.321739317228559, 1.2526798303781403, -0.41145613068348347), (0.20914281778571836, 1.218783556496604, -0.4010660350190128), (0.19990541095781347, 1.3179891346334074, -0.35346816433988354), (0.17509548383556886, 1.2589500202353476, -0.278631394216061), (0.26547227496263837, 1.2930946184676637, -0.2268447237082375), (0.36006207258216444, 1.3634324908262359, -0.21998819661434132), (0.463358750286101, 1.3200998916150415, -0.19054959223167434), (0.5520191313606883, 1.3877372366588756, -0.16036215212544197), (0.6421462628437602, 1.323017702736712, -0.13029171760101668), (0.6017638154271758, 1.257708398481445, -0.0628497002474029), (0.5057384748546646, 1.326214878753011, -0.05566555752444693), (0.40584340980019307, 1.3056039576382308, -0.10132113554557817), (0.3074463026097062, 1.3680575318595223, -0.11756151030040395), (0.20639656170174658, 1.3060695657959442, -0.12034624314741296), (0.1267551352665666, 1.3626564772300467, -0.17096285783716542)]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coords_B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          \"[(-0.3146743227763885, 1.7805242785059046, 0.3813268894087186), (-0.4297362112037039, 1.7762406834549411, 0.40234109190127426), (-0.49290010113505356, 1.8162519444744465, 0.47139778628382606), (-0.6043419247244062, 1.7955789422719715, 0.4978410477722312), (-0.6659142344252723, 1.8596155842294886, 0.556882064352095), (-0.7749530839411496, 1.879636735011165, 0.5874673234364716), (-0.8346217388565352, 1.9565552026654194, 0.6365160633300088), (-0.9469685786553786, 1.9743103937462239, 0.6618828734657884), (-1.004234259497289, 2.0498320369273384, 0.7153544243516344), (-1.114271747589156, 2.058988997362369, 0.7470395359049976), (-1.1774356375205057, 2.1416499656284222, 0.703981481799984), (-1.2457487576093023, 2.219313406335018, 0.7468991292068291), (-1.3205530284420322, 2.304085131582706, 0.7220237425146392), (-1.2857879230153901, 2.415893170521618, 0.7348007520479746), (-1.175188700724529, 2.3785513962730027, 0.723568216194493), (-1.0867467718384394, 2.4109266835060086, 0.668926609490576), (-1.057755045679238, 2.331369769624711, 0.6071242611800646), (-0.9456266580688923, 2.335560243044132, 0.5781770802409877), (-0.9182265121401745, 2.2659673437379015, 0.5082311434367018), (-0.813962403315748, 2.26140438379231, 0.4661793373352293), (-0.7856260337220397, 2.3614170160691494, 0.5073887032476906), (-0.8844912527450218, 2.4207354953618374, 0.48487682930800424), (-0.9786753534430521, 2.4594430535397453, 0.5304388028636897), (-1.074919146204061, 2.410957724049856, 0.49306722003450143), (-1.1903867315528722, 2.4418430651781784, 0.49791125112131546), (-1.2547052973377102, 2.3605168402975703, 0.5419521521135088), (-1.333472915018899, 2.3436307844444975, 0.6072412667618717), (-1.246747396185292, 2.2874163595365657, 0.6499951063541869), (-1.1309053213704847, 2.2954869009369316, 0.6669843168325781), (-1.055508108883261, 2.2252731907537497, 0.7107444044284345), (-1.063965329323674, 2.203668972235848, 0.7974221394311357), (-0.9480920470533669, 2.2039172965866283, 0.8150665811676469), (-0.8613665282197599, 2.2521232611818895, 0.8616114016105122), (-0.8181129948972052, 2.283381088836383, 0.7813221713744783), (-0.8715401587126551, 2.3240752418205344, 0.7076320559523657), (-0.8959443889134039, 2.2106220540577013, 0.6953230687462583), (-0.8535022494338409, 2.215464378897921, 0.6118278855687102), (-0.8650178005132223, 2.1007385288373377, 0.5952130929521016), (-0.8192988782061931, 2.1130926652886663, 0.5132389823380458), (-0.7198719249842167, 2.165737427654129, 0.5426307844879898), (-0.7096982944913215, 2.0932267172262278, 0.6120384956159629), (-0.7177186105547388, 1.9941453012648154, 0.5639960037259668), (-0.6388573705070508, 2.040116346703052, 0.5085821601821231), (-0.5648332860618128, 2.0687667686743505, 0.5747839183685816), (-0.570076138585759, 1.9588832434539865, 0.6079667013690758), (-0.5545972406579184, 1.9117636978933896, 0.5271626465730911), (-0.4552327023469414, 1.9775386103063701, 0.5173341777012944), (-0.41238486594588253, 1.951433512930572, 0.5983722436608935), (-0.43891120312060944, 1.8374215953784827, 0.5861802620365935), (-0.37674595176524944, 1.8354660411160864, 0.5102670405601455), (-0.2774750358207715, 1.8516071239168177, 0.5584265380319487), (-0.31030527900643345, 1.7985588344813372, 0.6337547315993612), (-0.3086200764094509, 1.9011788724413718, 0.6771170002170733), (-0.4063306195789449, 1.882026856887427, 0.7255339099688524), (-0.5108131805918691, 1.9366582140591333, 0.7183029650131731), (-0.5629608387318323, 2.0393713736507104, 0.7383577217349104), (-0.5981628485354697, 2.0014087885251444, 0.8186235508545828), (-0.48294492283065604, 1.9891167331615103, 0.8362211903583708), (-0.4339804251516602, 2.0817417160026306, 0.7968605126384616), (-0.5261984561532107, 2.1549663589390256, 0.8111819958516511), (-0.5722918679262362, 2.1312513834394893, 0.8918924461821902), (-0.6255005795531883, 2.233995583574914, 0.9150361502636352), (-0.5768481564291893, 2.2389620705905235, 0.9969634586449679), (-0.4838499390401467, 2.2934692655868396, 0.9611831517283561), (-0.5068810411989095, 2.409964426646734, 0.9604109148884292), (-0.48793811571060464, 2.4258261445528375, 0.8736863776530049), (-0.5712620218947467, 2.349373285056296, 0.8478515451899968), (-0.6651028405822805, 2.3952512088629905, 0.8908627970622878), (-0.7349451259905615, 2.4351072671632576, 0.8260183036247917), (-0.6528695180264065, 2.425205333675886, 0.7629288939144022), (-0.6884148098405405, 2.41179581873374, 0.6780062426388073), (-0.677398578049154, 2.3016018880749005, 0.644987267452843), (-0.6125494855208217, 2.349900974301705, 0.5795109438735885), (-0.5281645258496905, 2.36154117824454, 0.640260241947836), (-0.5297248986246743, 2.245108098272341, 0.6552135553027837), (-0.5295376538916764, 2.218909879265, 0.5685358203000823), (-0.43703875579062873, 2.2874163595365657, 0.5492767015346334), (-0.37496712680176775, 2.2464428416577857, 0.6184035992662693), (-0.3911013812951017, 2.137211167858221, 0.5877481368328086), (-0.35667955787895606, 2.1736527663352567, 0.5081141378548948), (-0.2626202870029245, 2.2242488528067805, 0.5464217653385399), (-0.23419029504271716, 2.121939220285221, 0.5852910196148593), (-0.24280355276062845, 2.0474108745072286, 0.5156492973232721), (-0.18541304209671938, 2.1217840175659837, 0.4615225151793067), (-0.10158981662458241, 2.1274333965462393, 0.5233950668389024), (-0.0972519803101271, 2.0108451138548027, 0.5150642694142366), (-0.08158583764928844, 2.0221438718153144, 0.42745048975707844), (-0.19346456561563646, 2.0102863840655467, 0.40121783831592606), (-0.24561222375559966, 2.060199578572423, 0.3328163751914942), (-0.3639196875548815, 2.052905050768247, 0.3366307571584056), (-0.4050199064479584, 2.018853574167473, 0.2573945771586359), (-0.5200193799642743, 2.0032401806121505, 0.2680186839867208), (-0.6086485535833619, 2.001781275051315, 0.3264512715411877), (-0.7129126624077884, 1.9471188773357613, 0.3166930060184755), (-0.7976096966339163, 1.9572691351739135, 0.3778401230708671), (-0.9130460745272277, 1.9368444573222188, 0.39064053372056406), (-0.9827947375690096, 2.007430654031571, 0.4396190702650171), (-1.0821592758799865, 1.9577657838754743, 0.4722636275891986), (-1.1704763749440774, 2.026210183059345, 0.5030828978371893), (-1.2882845194553645, 2.029376318531796, 0.491546147471009), (-1.2900945518743459, 2.1472683040648306, 0.49903450470666355), (-1.2671882795375815, 2.2213310416851093, 0.47006392265122504), (-1.2480581093162786, 2.1962192417124333, 0.3844158367684262), (-1.1359921366169325, 2.217078487177994, 0.3597978623562119), (-1.1563706050582225, 2.225117988034512, 0.27220748381541515), (-1.161176553205173, 2.34359974390065, 0.27253509944447507), (-1.0559450132602566, 2.349745771582467, 0.31402527875327346), (-0.9967756776328657, 2.270840709121968, 0.26607639132872296), (-0.9249049076171058, 2.342078757252119, 0.2204910166566759), (-0.900875166882353, 2.4076984669458623, 0.2920048282571768), (-0.8799349642420686, 2.3102932403522174, 0.33901767102727043), (-0.8046001666658443, 2.269071398122658, 0.2780343617894089), (-0.7481146722114259, 2.3723122469596434, 0.2693759487356832), (-0.7308569493201036, 2.377713301589119, 0.3558898759238547), (-0.6847947450025778, 2.269599087368066, 0.35923623556353784), (-0.6222862116367214, 2.297908063357041, 0.28711399493763995), (-0.5814980672986414, 2.390967613812027, 0.33181012718795294), (-0.560557864658357, 2.3368639458857294, 0.40922102011153183), (-0.515400676550322, 2.237844611012012, 0.3738151310567027), (-0.45978899084989444, 2.298094306620126, 0.30983647892457916), (-0.5002026457219784, 2.2201204604750546, 0.2503742422502098), (-0.546077605306506, 2.2319779482248228, 0.16914896735971935), (-0.6626686590533056, 2.227073542296908, 0.15985872416423547), (-0.6593606687703397, 2.1214425715836605, 0.11991301853529074), (-0.5967585130379842, 2.076620026267783, 0.18847828947425266), (-0.6816115845416106, 2.1058602185721846, 0.24691087702871956), (-0.7637183999612652, 2.0204987229913938, 0.2474959049377552), (-0.8580273304812943, 2.0576852945207715, 0.29474275887146306), (-0.961011933630234, 1.999949882964309, 0.2920282293735383), (-1.060251642119212, 2.0214920203945157, 0.3384092420018736), (-1.1355864396954365, 1.941686782162438, 0.371709030584175), (-1.2311436684354526, 1.9379929574445782, 0.425086977004575), (-1.2390079472213718, 1.8585602057386712, 0.4911951307255877), (-1.3435217156897956, 1.8149172010890016, 0.46521989156441096), (-1.3844971047608738, 1.8252226616463916, 0.5482002501820079), (-1.294057898722805, 1.7649419254944294, 0.581312829833418), (-1.24303370898083, 1.8611055303341715, 0.6166251144228013), (-1.3179940170910585, 1.95183704000059, 0.6113598632414818), (-1.2650661725636034, 2.0133593979064552, 0.6761809555626164), (-1.1518767314662688, 2.005102613243004, 0.6545115218119412), (-1.0765419338900446, 2.0402715494222896, 0.5936686192722479), (-0.9972125820098613, 1.9588211623662914, 0.5688634359291422), (-0.8975047616883879, 1.9649051089604133, 0.5214059719481816), (-0.8245105232746394, 1.8808473162212198, 0.4940266658053196), (-0.7257077191626565, 1.905027899878469, 0.4482774833187426), (-0.6365480188000746, 1.8547422188454212, 0.4045173957228865), (-0.5361536344576082, 1.910428954507945, 0.38319897871763237), (-0.45098848839898503, 1.8820578974312747, 0.3255386280030924), (-0.33976511699813017, 1.9231245369415968, 0.3316229182570617), (-0.23877779100116997, 1.9204550501707067, 0.28360382748342694)]\",\n          \"[(-0.9843863177994933, -0.3288669191989089, -0.5532200936009686), (-0.9020922576468405, -0.40156387288989537, -0.5203649262295342), (-0.8335294779140465, -0.31052195778500075, -0.4961915730281869), (-0.9191627358051648, -0.2552077086486481, -0.45023178049435714), (-0.942069008141929, -0.35885208455565226, -0.4117135429634591), (-0.8268198749816156, -0.3757381404087251, -0.3949115414159592), (-0.8066286512733234, -0.27054173730934294, -0.35756335970313213), (-0.911579324118743, -0.27178335906324536, -0.31663480718700776), (-0.8929484731854347, -0.3791836407758043, -0.28333501860470645), (-0.7831918521930648, -0.35161963783917066, -0.25658754260360295), (-0.8196421602166895, -0.2507068297907519, -0.21970738321800426), (-0.9002510177723595, -0.3124464715035495, -0.17405180519687294), (-0.8153043239022342, -0.3889303715439383, -0.15121231562812662), (-0.7456804906824509, -0.3011166729991899, -0.12261615143447079), (-0.8368062607415128, -0.2547421004909347, -0.07845824486047037), (-0.857278351549302, -0.35767254388944497, -0.03825512695155012), (-0.7436207986194722, -0.36509123386901193, -0.0129819212812159), (-0.7456804906824509, -0.2524451002462153, 0.014327181512561642), (-0.8483530192763938, -0.2720627239578734, 0.056870411057624144), (-0.7982962606549092, -0.3648429095182314, 0.09667570998840035), (-0.7128190400412894, -0.2962122670712754, 0.12995209745434017), (-0.790057492402994, -0.216096623400722, 0.15896948174250158), (-0.8575592186487991, -0.29857134840369, 0.19840036281149492), (-0.7633751179507687, -0.34839142127902445, 0.2377376394150428), (-0.72829793796913, -0.24300877491655687, 0.26818249180125087), (-0.8372431651185083, -0.21889027234700253, 0.2987911520019888), (-0.8369310905635114, -0.32023764800928717, 0.3446807411867343), (-0.7474593156459327, -0.27637735955268433, 0.39312105205487463), (-0.8113409770537748, -0.18306948474691775, 0.4178326309325346), (-0.726924809927144, -0.10521980077723633, 0.39688863178906336), (-0.7720195831241798, -0.016381764285518567, 0.34889294213178995), (-0.6618884726658137, 0.012392819861169895, 0.32366653869417866), (-0.6421653607900167, -0.0965284484999195, 0.2917942182099241), (-0.7426845749544818, -0.0917482047473952, 0.24513239218525157), (-0.7157525408582591, 0.01459669847434673, 0.2127452471410458), (-0.6103025487248448, -0.02544560308900614, 0.18379806620196867), (-0.6614827757443178, -0.11751185614087027, 0.143524744943964), (-0.7446506446509616, -0.045994443116091195, 0.10861027933272474), (-0.6683484159542472, 0.033748714028291514, 0.07685496443027719), (-0.6061519571433875, -0.05496516028803608, 0.041074657513665236), (-0.704299404689877, -0.09674573230685236, 0.002205403237345996), (-0.7356004825560547, 0.007643616652493198, -0.03207723223213505), (-0.6275290641606674, 0.03176211922204765, -0.0635751348546069), (-0.6156390236152899, -0.0786801357875722, -0.09214789793190135), (-0.7173753285442424, -0.07275139191268819, -0.13787367930211694), (-0.6852316493795734, 0.030085929854279325, -0.17437942082593283), (-0.5811235778326452, -0.01861668344254289, -0.19930160975084563), (-0.6375466573760643, -0.11443884229996179, -0.2297464621370536), (-0.702364542448897, -0.041276280451261985, -0.28120551701581725), (-0.6004722002424461, 0.00323585942613964, -0.3114865615874953), (-0.5598400931818643, -0.10410234119872423, -0.33226675291643665), (-0.6600784402468324, -0.1362913851686443, -0.37352292106162094), (-0.6650092182157815, -0.03509921222559741, -0.4190146912682223), (-0.5510707981864547, -0.04422513211678018, -0.4422051975823899), (-0.5658319246378027, -0.1560642115995403, -0.46832084344173514), (-0.6597039507808362, -0.12884165464522976, -0.5187502492005963), (-0.604154679991408, -0.037613496277249796, -0.5571046789169644), (-0.5073179455759051, -0.10314008433944978, -0.5725728168318633), (-0.568515765810775, -0.1904571341826372, -0.6110910543627615), (-0.6620133024878124, -0.13486352015165656, -0.6469883668611803)]\",\n          \"[(-0.5119366489898576, -0.3940831018226333, 0.8716738816459229), (-0.5208931887182653, -0.2998750512452875, 0.8184831441564142), (-0.4493969081685014, -0.30766622775102515, 0.7479755805594543), (-0.35964426615142553, -0.23726627430475825, 0.7243872552671425), (-0.37190879616279926, -0.1500423460931135, 0.6639655728219551), (-0.37674595176524944, -0.19958305407381988, 0.5829275068623558), (-0.30612347996947653, -0.11189351770446182, 0.5554077940213253), (-0.25110473592354304, -0.018740845617933172, 0.5916795243815272), (-0.3184504248918497, 0.027975172872645285, 0.6574834635898417), (-0.28939628382164884, 0.13990737398694797, 0.6393007961770177), (-0.3174829937713596, 0.12280403432694224, 0.5539101225741945), (-0.4217471025957861, 0.07242523166235171, 0.574409500506799), (-0.4458392582415381, 0.1623807277325817, 0.629074508327077), (-0.4216846876847868, 0.2396716819130071, 0.5638555970277983), (-0.48587842364762585, 0.17973239174336797, 0.5040891458407304), (-0.579781657246159, 0.17631793192013637, 0.5588945603591771), (-0.5857422812465977, 0.29358910657621956, 0.5496277182800545), (-0.5835265519061206, 0.2890571871744757, 0.4602822560121513), (-0.6675994370222549, 0.26022052194009204, 0.4016156572940703), (-0.6339577999936012, 0.17752851313019116, 0.34266824517965216), (-0.6654461225927771, 0.16259801153951467, 0.25732437380955164), (-0.6406674029260322, 0.0908943552516501, 0.18880590510331263), (-0.5998480511324524, 0.13323365705972248, 0.11160562222698656), (-0.5931072407445218, 0.07317020471469318, 0.034569147165190384), (-0.4927752713130548, 0.07444286701244318, -0.012841514583047373), (-0.47520547386673573, 0.1719101746937828, -0.06153923773116341), (-0.5439554983325279, 0.2396096008253119, -0.009963177270592713), (-0.5029801092614498, 0.3449301661000843, 0.015707847377885557), (-0.4957087721300246, 0.3558564375344255, 0.10423427057313916), (-0.445558391142041, 0.46257382728233815, 0.1060361565329685), (-0.4501770945559934, 0.5467868227407695, 0.04341476914980732), (-0.35964426615142553, 0.6224636686411218, 0.03655824205591114), (-0.39294262116958273, 0.7321299100545526, 0.05717462557032257), (-0.4822583588096631, 0.7072664344326567, 0.11317349702320173), (-0.4795121027256914, 0.7568692235010582, 0.1937903428882952), (-0.42789497132922283, 0.6812854992322486, 0.2506784567629083), (-0.48740758896711006, 0.6633440648883588, 0.32703629945022317), (-0.48135334260017243, 0.5464453767584463, 0.3383624397691507), (-0.40096293723300014, 0.46102180008996024, 0.3513032571170163), (-0.4041148902384677, 0.35247301825504157, 0.3149145211750075), (-0.3597066810624249, 0.2469351691733363, 0.33777741186011523), (-0.3525289662974988, 0.1517338211928685, 0.285335510094172), (-0.40021395830100787, 0.05814658149247391, 0.32537482018856234), (-0.39060206200710684, -0.008776831042866242, 0.25203572151187065), (-0.350562896601019, 0.0037945892153957482, 0.16875114838157532), (-0.27756865818727056, 0.07649154290638213, 0.12562289092747733), (-0.2836541120097079, 0.18299164884736183, 0.08792369246922904), (-0.2190234716698734, 0.25075315606658616, 0.034569147165190384), (-0.19202902266265126, 0.3622197490231755, 0.05586416305408308), (-0.18263557855724802, 0.4217555121227963, -0.019838448375112075), (-0.16671977625241186, 0.5260517394505992, -0.05826308144056453), (-0.1840087065992339, 0.5615310810683607, -0.14283471597073807), (-0.13931963032369396, 0.6415225625635238, -0.1989037907727015), (-0.2047616645065202, 0.7234385577772358, -0.24086199240872835), (-0.23584429018420014, 0.6439747655274811, -0.3023835273229027), (-0.2605918023954453, 0.5548573641411352, -0.24774192061898598), (-0.1606655298854742, 0.49181401958674004, -0.25361560082570245), (-0.15320694802105098, 0.43165744561016794, -0.17709395032385758), (-0.06763610504093197, 0.4094634567591624, -0.11852095607122219), (-0.07737283115683176, 0.34399894978465745, -0.04543926967450608), (-0.0274096949018462, 0.39229803601146157, 0.026565965369584613), (-0.042794970463187754, 0.29287517406772556, 0.07198753222710177), (-0.1093916804995021, 0.19789110989419084, 0.08424971720048595), (-0.15408075677504193, 0.18606466268827032, 0.16620042669818044), (-0.19514976821261917, 0.08825590902460756, 0.20446125194910283), (-0.24904504386056428, 0.04181925542865715, 0.27489861219697853), (-0.2157154813869074, 0.09744391000348541, 0.34870573320089854), (-0.18922035166768017, 0.1998777047004347, 0.30803459296474983), (-0.2390586581006671, 0.30361520223898136, 0.32860417424643834), (-0.2753217213912937, 0.3722458446859375, 0.2609047446128491), (-0.31092942811642715, 0.4848919783087341, 0.25606071352603504), (-0.24177370672913914, 0.5160566843316846, 0.323900549857793), (-0.18940759640067825, 0.6097680862074696, 0.28702039047219435), (-0.2748224021032989, 0.687897135071779, 0.30649011928489617), (-0.28203132432372463, 0.6584396589604442, 0.3927700353094533), (-0.20675894165849965, 0.7368170321755342, 0.4278249076188611), (-0.24951315569305949, 0.8363019752069651, 0.39218500740041784), (-0.36148550602590657, 0.8605446399519098, 0.36920511113350296), (-0.3925369242480869, 0.9008973469537384, 0.28922009541016774), (-0.3248791607247835, 0.8259033930180324, 0.2434475118072294), (-0.3490649387370344, 0.7651880892522044, 0.16928937405788788), (-0.3272509273427591, 0.6525109150855601, 0.14712851686362283), (-0.2188674343923749, 0.6456199143514016, 0.11125460548156524), (-0.24180491418463873, 0.5565645940527509, 0.05481111281781912), (-0.323755692326795, 0.4799875723808195, 0.02623834974052466), (-0.33330517370969676, 0.375598223421474, 0.0667924843948664), (-0.37949220784922116, 0.2895538358760366, 0.016901304312318045), (-0.40302262929597893, 0.17858389162100827, 0.04128526756091803), (-0.32915458212823945, 0.10116877526519269, 0.0026500244482129463), (-0.38847995503312865, 0.006929684143999319, 0.03311827795078237), (-0.4909028239830741, -0.002723924992591959, 0.07765060238656546), (-0.47689067646371835, 0.058270743667864194, 0.15318940600123074), (-0.5196136830427786, 0.068948690751425, 0.23549113224434637), (-0.494897378287033, 0.17638001300783143, 0.26769106835766104), (-0.5163369002153123, 0.2294903835310072, 0.3454061757939383), (-0.5351237884261189, 0.3463580311170721, 0.3500161957171382), (-0.5383693637980853, 0.4223763229997474, 0.4186984722379071), (-0.5447044772645202, 0.5401441463573916, 0.4254379937499963), (-0.4458392582415381, 0.598779733685433, 0.4471542297333944), (-0.5084102065183937, 0.6442851709659566, 0.514970664948791), (-0.5301618030016699, 0.5372263352357209, 0.5489490859055735), (-0.42043638946479966, 0.49777380400547167, 0.5323810955216878), (-0.3738124509482797, 0.5880397055141773, 0.5784110914046018), (-0.44087727281708916, 0.5570302022104644, 0.6479124069980206), (-0.3984039258820265, 0.44668106883238723, 0.6418983200931355), (-0.28780470359116517, 0.48945493825432546, 0.6406112586932574), (-0.3083392093099538, 0.5442414981452696, 0.7180455527331976), (-0.3425425805376016, 0.4409385682205887, 0.7534046395553038), (-0.25154164030053855, 0.3760948721230349, 0.7225385670745905), (-0.15957326894298546, 0.4284602695938694, 0.6793167051550467), (-0.12527627534883856, 0.32282929888062145, 0.6486378416052245), (-0.20176574877855105, 0.3319241782279566, 0.5807746041571052), (-0.14474972758063803, 0.43053998603165594, 0.555548200719494), (-0.04001750692371639, 0.3762190342984253, 0.5636917892132683), (-0.07849629955482024, 0.2919749982961462, 0.5079737311567263), (-0.1146657404789478, 0.37041445259893135, 0.4468032129879731), (-0.01561327672296765, 0.43463733781953384, 0.45319171775464095), (0.050608943847350533, 0.3380702059097736, 0.44123374729395504), (-0.0029430497900980275, 0.3230155421437066, 0.3625123918541367), (0.010757023174260921, 0.4350719054333998, 0.3376136040455853), (0.12694237999956468, 0.42442499889368646, 0.35514104020028914), (0.13649186138246638, 0.3283234751416396, 0.30417340876511545), (0.07613664244608774, 0.38050262934938855, 0.2380652550441026), (0.14813224228384644, 0.4737173825236124, 0.23865028295313825), (0.24244117280387553, 0.4017033207972723, 0.23296381167731303), (0.19719036232934134, 0.34170194953993804, 0.16381351282931564), (0.15693274473475585, 0.43684121643271057, 0.12098946988791608), (0.26129047592568144, 0.49178297904289253, 0.1303967186652071), (0.3150609217516278, 0.3994063205525529, 0.09215929453064609), (0.23900835269891088, 0.40940137567146717, 0.024132249267996907), (0.2676567968476159, 0.523661617574337, 0.01383575806897196), (0.3815952168769427, 0.493303965691423, 0.008008880094978212), (0.361279163346652, 0.41070507851306476, -0.05367646263372617), (0.2952441875093319, 0.4833399511163562, -0.10408246727622575), (0.3789113757039704, 0.5669631762416837, -0.09980006298208581), (0.47041163522902835, 0.4950111956030388, -0.11648505894777861), (0.4240061489010061, 0.4271876072961193, -0.18121254680346763), (0.37572821524300326, 0.44959887995405795, -0.2607997435486586), (0.27823612426200695, 0.393105090151498, -0.28970012225501285), (0.34027654579536815, 0.2991453639249327, -0.31801547305233163), (0.4004757274542484, 0.2921302010153841, -0.24165763036501664), (0.3017665457087646, 0.3034289589758962, -0.1927960994023707), (0.2513352976212838, 0.21244912495869658, -0.23470749880567474), (0.3507622508432602, 0.14701565852803927, -0.23299921731129103), (0.36505526546211314, 0.16641599843276453, -0.14587686109772272), (0.25058631868929154, 0.1433528743540272, -0.1293556729465599), (0.2592619913182024, 0.03812543071079747, -0.16955879085548023), (0.35865773708467885, 0.013044671281968689, -0.12434783404521593), (0.30794562189770097, 0.04150884999018161, -0.0466093254925772), (0.21011024890620836, -0.021162008038042864, -0.06511960853446071), (0.2835101842414525, -0.11096230138903508, -0.08236623129282762), (0.32429832857953267, -0.10115348953320592, 0.0008949407211063456), (0.2192852408231138, -0.10838593624968751, 0.04194049881903777), (0.19428806896787132, -0.2089883388596307, 0.08553677860036424), (0.10731289049026672, -0.23254811163992903, 0.027338202209511518), (0.1827725178884899, -0.23118232771063638, -0.04146107989306473), (0.19463135097836765, -0.3373099471254453, -0.08018992747121545), (0.30048704003327786, -0.38796811468466386, -0.09266272249185258), (0.3242047062130336, -0.40469896781849896, -0.17894263851640982), (0.41043090575864577, -0.4657557175666502, -0.22087743903607532), (0.44485272917479146, -0.36465666625514603, -0.2593488743342505), (0.42534806948749226, -0.2959949832643425, -0.18846689287550794), (0.32617077590951343, -0.26169518231278827, -0.14683630686854096), (0.21516585669715627, -0.26200558775126387, -0.1785916217709885), (0.1332462860104997, -0.18195202516840564, -0.15675838020578323), (0.01940148834767184, -0.16652487487616813, -0.17882563293460274), (-0.016736745120956017, -0.05577221442807265, -0.19328752284596054), (-0.0750946869053552, 0.0036393864961578666, -0.25658754260360295), (-0.034837069310769714, 0.09362592311023545, -0.3053788702171645), (-0.12003342282489256, 0.15915251117243545, -0.2683115019006745), (-0.082209986759282, 0.13422695446284444, -0.1861033801230045), (0.030261682861560103, 0.15688655147156352, -0.20903647415719656), (-0.004690667298080064, 0.2593513867123604, -0.24420835204841151), (-0.06117616175249857, 0.28660498421051844, -0.1685291417355777), (0.03703370070499034, 0.2652801305872443, -0.12074406212555719), (0.10790583214476068, 0.3338797324903528, -0.1699800109499858), (0.02695369257859411, 0.4129710382139367, -0.19534682108576557), (0.027359389500089985, 0.3926084414499371, -0.28305420520836944), (-0.05040958960510934, 0.35231781553580366, -0.3430546675590515), (-0.06941493000441372, 0.23985792517609247, -0.3645602934951968), (-0.028345918566836485, 0.2647834818856834, -0.44618338736383145), (0.07279744470762214, 0.3072469458691461, -0.41316441217786715), (0.08643510276098167, 0.2099969219947393, -0.36306262204806594), (0.0683659860266678, 0.14664317200186863, -0.4366825341210947), (0.1523140413208034, 0.20074683992816636, -0.4848186304765366), (0.23151856337898793, 0.19456977170250178, -0.419108295733668), (0.21029749363920644, 0.08096138122043077, -0.3994045557573519), (0.22686865250953578, 0.054701081125394686, -0.4851462461055965), (0.3299156705694748, 0.11342979008497903, -0.4834379646112128), (0.3663347711375999, 0.05991589249178492, -0.4089522112328115), (0.34002688615137067, -0.04341807797674362, -0.4470024264364812), (0.4009126318312438, -0.01510910198776858, -0.5206457396258714), (0.4918199497018079, 0.0105924683180114, -0.4669401775764113), (0.48046043589992476, -0.0988564892884865, -0.43380419680864), (0.4587712543276483, -0.061887201566042015, -0.3509174426564887), (0.34954516007877284, -0.10664766579422409, -0.3417208039264505), (0.2719322182510719, -0.1791894167659727, -0.3803326459227943), (0.157993798221745, -0.14858344053227826, -0.3872359752494133), (0.0669616505291822, -0.22053542117092315, -0.40497402145136996), (-0.039268527991724075, -0.17779259229283254, -0.38365560444611596), (-0.039861469646217916, -0.1422511695873759, -0.299060568799581), (0.052512598632830934, -0.21237175813901485, -0.28104170920128724), (0.15989745300722538, -0.16230336091289996, -0.2811821158994558), (0.2643800140201495, -0.21522748817299034, -0.26992617892961257), (0.3482032394922865, -0.1453862645159795, -0.2359243568564686), (0.4522176886727157, -0.19207124246271035, -0.260378523454153), (0.536789893076845, -0.20454954108942955, -0.19934841198356845)]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embeddings_A\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          \"tensor([-1.5681, -0.1808,  1.0557, -1.2689, -0.3231,  1.4444, -0.3534, -1.1651,\\n        -0.0851,  0.5490,  0.7725,  0.4256,  0.2550,  1.0292,  1.9616,  0.8425,\\n         0.2334, -0.0033, -1.1211,  1.0336, -1.2742,  1.0117,  0.9435, -0.1552,\\n        -0.2775,  1.7462, -1.8101, -0.0646, -0.5227,  1.3919, -0.0670, -0.9132,\\n        -1.2309,  0.5169, -0.2262, -0.9008,  0.9982,  1.2483,  0.2122,  1.1596,\\n         1.4483,  0.4658, -1.4015,  0.7118,  0.1738, -1.9527,  1.1646, -0.2706,\\n        -0.4584, -0.0136, -0.3105,  0.8400, -0.5893, -1.3326,  0.5802, -0.9855,\\n         0.6858,  0.1478,  0.4120,  0.0989, -1.9927, -1.5802, -0.3040, -0.6081,\\n        -0.5024, -0.1566, -0.7994, -0.3840,  0.6649,  0.0267,  0.8498, -0.3532,\\n        -0.8132,  0.9210,  0.2584, -0.2222,  0.7512, -0.1087, -0.3180, -0.7165,\\n        -0.3411, -0.8527,  0.5198,  0.6889,  0.3240, -0.5234, -1.2592,  0.0439,\\n         0.1054, -0.2058, -1.3160, -0.8292, -1.7298,  1.1839, -0.9930, -0.2023,\\n        -0.2821, -0.4522,  1.4520,  0.4376, -1.3315,  2.1029,  0.3323, -0.3259,\\n        -1.5801, -0.3708, -0.0836, -0.2031, -1.3899, -0.3245,  1.2669, -1.1403,\\n         1.9234,  0.4835,  0.4360, -1.3580,  0.8874, -1.4497, -1.2362,  2.0237,\\n        -1.1363, -0.3027, -0.4730,  1.5161, -1.8301,  0.2950,  1.7171,  0.0467])\",\n          \"tensor([-0.8630,  0.1531,  0.7046,  0.0792,  1.4462, -0.4757, -0.2314,  1.0487,\\n         1.3049, -0.5704, -0.6190, -0.5011,  1.3892,  1.6233, -1.2061,  0.6904,\\n         1.2767, -0.2564, -0.1260,  1.5888, -1.8102,  0.3862,  0.0045, -1.9662,\\n         1.3262, -0.4886,  1.4700, -0.8781,  0.8432, -0.2065, -0.6032,  0.2375,\\n         2.1450, -0.7414,  0.5043,  1.4608,  0.9348,  0.4254, -0.9740, -0.4809,\\n        -0.3530, -1.6107,  0.2935, -0.0728,  0.7354, -0.9125, -1.4938, -0.2978,\\n         1.1730,  1.9740,  0.1040, -1.3079, -0.2160, -0.7094,  0.0678,  1.0142,\\n        -0.5117, -0.7375,  0.0051, -0.5245, -0.8148,  0.3014, -0.5920, -0.3421,\\n        -0.1263, -0.2356,  1.2796, -0.1685, -0.4012,  0.2485, -1.2763,  0.4648,\\n        -1.4868,  0.7210, -0.1893, -0.0761, -0.8691, -1.5179, -0.5409,  1.0789,\\n        -0.8410,  1.2977, -0.1313,  1.1512, -0.6757,  0.1316,  0.4615,  0.1265,\\n        -1.0392,  0.2896,  0.8939, -0.4364,  0.9631,  0.8103,  1.6472,  0.4623,\\n         1.5046, -1.6123,  0.0872,  0.3206, -0.7229,  0.1748, -2.0442,  0.3900,\\n        -0.5517, -0.7232, -0.0654,  1.8884, -0.5867, -2.1811, -0.2026,  1.0235,\\n         1.0155, -0.9076,  1.0060, -0.4969, -0.6558,  0.4739, -1.4218, -0.7377,\\n        -0.6508,  0.4669, -0.8338, -0.2962,  0.2202,  0.7396,  0.6569, -1.5014])\",\n          \"tensor([ 1.5128,  0.0807, -1.6357, -0.2594, -2.0366,  1.3442,  1.1053, -0.2137,\\n        -0.1628,  1.5940, -1.6152,  0.1387, -0.6860, -0.9350, -0.0629,  0.2967,\\n         1.0814, -0.4932,  1.3264, -0.1572,  0.7045,  0.4133,  2.7720,  0.9585,\\n         0.5072, -1.1573,  0.6967, -0.7399,  0.1606, -1.5811, -1.5153, -0.1704,\\n        -1.5994, -0.2262,  0.6019, -0.0812, -0.7248,  1.7941, -0.5842, -0.5628,\\n         0.8534,  0.6177, -0.4684,  0.5127,  1.3192, -0.1889, -2.5708, -0.7516,\\n         0.2638, -1.3506, -0.4633, -0.7187,  1.3043,  1.3957, -0.2243,  0.6370,\\n        -0.6786,  2.0596,  1.3210,  1.0417,  1.2237, -0.7451,  1.4961,  1.3012,\\n         0.0178, -1.4682, -1.3849, -1.2417,  0.2755,  0.2253, -0.2311,  2.0047,\\n         0.4584, -1.0942,  0.8791, -1.4589, -2.6823, -1.7529,  0.7817, -0.7298,\\n        -1.2145,  0.2574,  1.7379, -2.6001,  1.0293,  0.7322, -0.4310,  0.2514,\\n         0.5687,  0.1289, -1.3457, -0.3717, -1.2128, -1.1836,  2.2803,  1.3785,\\n        -0.2167,  1.5373, -0.4364, -0.2441, -0.1829, -1.2052, -0.8927, -0.8828,\\n         2.5360, -1.8170, -0.4057,  1.2894, -1.6113, -0.5040,  2.0529, -0.8952,\\n         1.2848, -0.6034,  1.2263,  2.2376, -0.3673,  0.9538,  0.1958,  0.9149,\\n         0.5447,  0.4701, -1.2625,  0.4486, -0.7814, -0.4215,  1.0829, -0.0247])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sequence_A\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 121,\n        \"samples\": [\n          \"PQITLWQRPLVTIKIGGQLKEALLDTGADDTVLEEMNLPGRWKPKMIGGIGGFIKVRQYDQILIEICGHKAIGTVLVGPTPVNIIGRNLLTQIGCTLNF\",\n          \"MHHHHHHAMEEVTIKANLIFANGSTQTAEFKGTFEKATSEAYAYADTLKKDNGEWTVDVADKGYTLNIKFAG\",\n          \"MVGLTTLFWLGAIGMLVGTLAFAWAGRDAGSGERRYYVTLVGISGIAAVAYVVMALGVGWVPVAERTVFAPRYIDWILTTPLIVYFLGLLAGLDSREFGIVITLNTVVMLAGFAGAMVPGIERYALFGMGAVAFLGLVYYLVGPMTESASQRSSGIKSLYVRLRNLTVILWAIYPFIWLLGPPGVALLTPTVDVALIVYLDLVTKVGFGFIALDAAATLRAEHGE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embeddings_B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          \"tensor([ 1.0309,  0.9820,  0.0689, -2.7654, -0.2004,  0.4183,  0.8815,  0.6381,\\n        -1.8780,  1.3888,  1.9668,  0.4345,  1.1711,  1.0936, -0.7996,  1.1466,\\n         0.3513,  1.2945, -0.0241,  0.7606,  0.1370,  2.5141, -0.8906,  0.2287,\\n         0.5220, -0.1891, -0.7183, -0.9890, -0.1238, -2.2073, -0.3712,  0.4978,\\n        -1.2222, -1.1830,  0.6501, -1.7094,  0.0507,  1.2582,  1.5682,  0.9454,\\n         0.7421, -1.5698, -0.7268, -0.4780,  1.3710, -0.4022,  1.3600,  0.2452,\\n         1.0034,  0.9613,  0.0638, -0.5075, -0.5424, -0.4834,  0.4145, -1.0258,\\n         0.8361, -0.1281, -1.3498,  0.5546, -0.0946, -1.5358, -0.6769, -0.2871,\\n        -0.9680, -0.7473,  0.1236, -1.1343,  0.3378, -0.6606,  0.9559,  1.1120,\\n        -0.2161, -0.1168, -0.1413,  0.0333, -2.3240, -0.1731,  0.6156, -0.5546,\\n         1.0807,  1.6435, -0.5196,  1.4074, -0.4950,  0.1121, -0.1260,  0.4201,\\n        -0.3927,  0.3722,  0.5531,  2.5552, -0.2938,  0.2009,  0.6864, -1.6848,\\n         0.6256, -0.0208,  0.3926,  1.4395, -0.3013,  0.5103, -0.8481, -0.2265,\\n        -0.2872,  0.0988, -0.0332,  0.2519, -0.9985,  0.2458,  0.4093, -0.1596,\\n         1.7661, -0.3277,  2.1580,  0.1685, -0.1496, -0.1543, -0.5908, -0.7235,\\n        -0.2293, -0.3532, -0.5261,  0.2071,  0.5290, -0.5700, -0.3222, -0.1330])\",\n          \"tensor([-9.2912e-03, -5.3865e-01,  8.7402e-01, -4.1492e-01, -1.2486e+00,\\n        -4.2195e-01,  9.3887e-01, -1.0537e+00, -5.3304e-01,  1.3528e+00,\\n         3.5892e-01, -1.7919e+00, -4.5601e-01, -3.0711e-01, -3.5784e-01,\\n         4.1728e-01,  3.2821e-01, -4.1010e-01, -3.2762e-01, -4.3551e-01,\\n         8.7176e-02,  2.9437e-01, -5.3246e-02, -2.6816e-02,  6.4967e-01,\\n        -2.2794e+00, -1.6096e-01,  5.8654e-01,  7.9251e-01,  3.0149e-01,\\n         5.2417e-02,  5.6304e-01,  8.7330e-01, -6.2660e-01, -4.9606e-01,\\n        -2.0042e+00,  1.2612e+00, -1.6417e+00, -1.6201e+00, -5.1233e-01,\\n         9.9481e-01, -5.7460e-01, -1.2091e+00,  4.8395e-01, -6.3984e-01,\\n         3.5234e-01,  1.4227e+00,  3.9668e-01, -5.2180e-01,  5.9164e-02,\\n         2.8231e-01, -3.6530e-01, -6.8105e-01, -1.2349e-01,  2.4872e-02,\\n         5.8322e-01, -1.1497e+00,  1.4891e+00, -1.5658e-01,  1.2166e+00,\\n         1.1445e+00,  9.6561e-01,  1.8928e-02,  1.8270e-01, -6.4987e-01,\\n        -4.1915e-01, -2.4704e-01,  2.2420e+00, -1.1660e+00,  7.6981e-01,\\n        -9.8312e-01, -1.5397e-01, -3.3396e+00, -6.7715e-01, -1.2753e+00,\\n         4.0914e-01,  8.3573e-01,  7.3190e-01,  1.2237e+00,  1.2870e+00,\\n        -5.7443e-01, -9.3982e-01, -1.0869e-01,  1.2888e-01,  4.1202e-01,\\n        -1.2858e+00,  2.1628e+00,  8.4284e-01, -2.3359e+00,  4.3197e-01,\\n        -1.8854e+00,  1.0753e-03, -3.6151e-01,  5.5223e-02, -8.1803e-01,\\n        -1.7234e-01, -1.3257e+00, -7.5512e-01,  8.7852e-01, -1.9024e+00,\\n         9.8253e-01,  6.3122e-01, -5.6989e-01, -1.3036e+00, -5.2252e-01,\\n        -3.9007e-01, -1.4658e-02,  2.3515e+00, -2.3174e+00, -1.3790e+00,\\n        -1.2711e+00,  6.1030e-01,  4.4324e-01,  9.1555e-01, -3.1726e-02,\\n         1.0947e+00,  6.9858e-01,  1.5376e+00, -2.0013e+00,  1.2934e+00,\\n        -7.9888e-01,  6.7030e-01,  2.2593e-01, -1.8002e+00, -1.0392e+00,\\n        -3.0591e-01,  2.1284e+00, -6.9367e-01])\",\n          \"tensor([-0.4434, -0.8970, -1.1061, -0.0786,  1.3523, -0.1806, -0.5711, -0.1442,\\n         0.6402,  0.4722, -0.6368, -0.1518, -0.6738,  1.1291,  0.5971,  0.9328,\\n         0.6283, -1.1649,  0.0624, -1.1259,  0.6410,  1.3748, -1.2245, -1.1859,\\n         1.5754, -0.4621,  1.5135, -0.6170, -0.4772,  1.5874,  0.7793, -0.1133,\\n        -0.9537, -1.3149, -0.5169, -0.3845, -0.6416,  0.0153, -1.4080, -0.1829,\\n        -2.0964, -1.5082, -0.0100, -0.9351,  0.4715,  1.2336,  1.8367, -1.1039,\\n         1.3343, -0.9520,  1.2690, -0.7074,  1.1171, -0.6297, -0.1099,  1.7396,\\n         0.9224,  0.5215, -1.0609,  0.6762,  0.6625,  0.4705,  2.3411,  0.3443,\\n         1.5228, -0.7974,  0.0702,  0.1856,  0.1072, -0.4224,  1.1231, -0.8116,\\n        -0.1817, -0.1281,  0.7529,  0.3351, -0.1668, -0.2500,  0.3917,  0.6104,\\n         0.0607, -0.0504,  0.8434, -1.8429,  0.4257,  0.6524,  0.6931,  0.0394,\\n        -0.0987,  1.8621, -1.0068,  0.5215,  0.1307,  1.2698,  0.3232, -0.2017,\\n        -0.0555,  1.0384,  0.7496,  1.0282, -0.8543,  1.1941, -0.1516, -0.2607,\\n        -1.1732,  1.0285,  1.4344, -1.1166, -0.0849, -0.8540,  1.4893,  0.0929,\\n         0.7511,  1.3393, -0.2636, -0.2031, -1.0880, -0.8983, -0.3638, -0.0563,\\n         0.9928, -0.6545,  0.2280,  1.7471,  0.6904,  1.2788, -0.5104, -1.4434])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sequence_B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 118,\n        \"samples\": [\n          \"DDFAKLEEQFDAKLGIFALDTGTNRTVTYRPDERFAFASTIKALTVGVLLQQKSIEDLNQRITYTRDDLVNYNPITEKHVDTGMTLKELADASLRYSDNTAQNLILKQIGGPESLKKELRKIGDEVTNPERFEPELNEVNPGETQDTSTARALATSLQAFALEDKLPSEKRELLIDWMKRNTTGDALIRAGVPEGWEVADKTGAGSYGTRNDIAIIWPPKGDPVVLAVLSSRDKKDAKYDDKLIAEATKVVLKAL\",\n          \"DIVLTQSPASLAVSLGQRATMSCRAGESVDIFGVGFLHWYQQKPGQPPKLLIYRASNLESGIPVRFSGTGSRTDFTLIIDPVEADDVATYYCQQTNEDPYTFGGGTKLEIK\",\n          \"GAVFIFVGALTVLFGAIAYGEVTAAAATGDAAAVQEAAVSAILGLIILLGINLGLVAATL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_sequence_A\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 121,\n        \"samples\": [\n          \"[13, 14, 8, 17, 10, 19, 14, 15, 13, 10, 18, 17, 8, 9, 8, 6, 6, 14, 10, 9, 4, 1, 10, 10, 3, 17, 6, 1, 3, 3, 17, 18, 10, 4, 4, 11, 12, 10, 13, 6, 15, 19, 9, 13, 9, 11, 8, 6, 6, 8, 6, 6, 5, 8, 9, 18, 15, 14, 20, 3, 14, 8, 10, 8, 4, 8, 2, 6, 7, 9, 1, 8, 6, 17, 18, 10, 18, 6, 13, 17, 13, 18, 12, 8, 8, 6, 15, 12, 10, 10, 17, 14, 8, 6, 2, 17, 10, 12, 5]\",\n          \"[11, 7, 7, 7, 7, 7, 7, 1, 11, 4, 4, 18, 17, 8, 9, 1, 12, 10, 8, 5, 1, 12, 6, 16, 17, 14, 17, 1, 4, 5, 9, 6, 17, 5, 4, 9, 1, 17, 16, 4, 1, 20, 1, 20, 1, 3, 17, 10, 9, 9, 3, 12, 6, 4, 19, 17, 18, 3, 18, 1, 3, 9, 6, 20, 17, 10, 12, 8, 9, 5, 1, 6]\",\n          \"[11, 18, 6, 10, 17, 17, 10, 5, 19, 10, 6, 1, 8, 6, 11, 10, 18, 6, 17, 10, 1, 5, 1, 19, 1, 6, 15, 3, 1, 6, 16, 6, 4, 15, 15, 20, 20, 18, 17, 10, 18, 6, 8, 16, 6, 8, 1, 1, 18, 1, 20, 18, 18, 11, 1, 10, 6, 18, 6, 19, 18, 13, 18, 1, 4, 15, 17, 18, 5, 1, 13, 15, 20, 8, 3, 19, 8, 10, 17, 17, 13, 10, 8, 18, 20, 5, 10, 6, 10, 10, 1, 6, 10, 3, 16, 15, 4, 5, 6, 8, 18, 8, 17, 10, 12, 17, 18, 18, 11, 10, 1, 6, 5, 1, 6, 1, 11, 18, 13, 6, 8, 4, 15, 20, 1, 10, 5, 6, 11, 6, 1, 18, 1, 5, 10, 6, 10, 18, 20, 20, 10, 18, 6, 13, 11, 17, 4, 16, 1, 16, 14, 15, 16, 16, 6, 8, 9, 16, 10, 20, 18, 15, 10, 15, 12, 10, 17, 18, 8, 10, 19, 1, 8, 20, 13, 5, 8, 19, 10, 10, 6, 13, 13, 6, 18, 1, 10, 10, 17, 13, 17, 18, 3, 18, 1, 10, 8, 18, 20, 10, 3, 10, 18, 17, 9, 18, 6, 5, 6, 5, 8, 1, 10, 3, 1, 1, 1, 17, 10, 15, 1, 4, 7, 6, 4]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_sequence_B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 118,\n        \"samples\": [\n          \"[3, 3, 5, 1, 9, 10, 4, 4, 14, 5, 3, 1, 9, 10, 6, 8, 5, 1, 10, 3, 17, 6, 17, 12, 15, 17, 18, 17, 20, 15, 13, 3, 4, 15, 5, 1, 5, 1, 16, 17, 8, 9, 1, 10, 17, 18, 6, 18, 10, 10, 14, 14, 9, 16, 8, 4, 3, 10, 12, 14, 15, 8, 17, 20, 17, 15, 3, 3, 10, 18, 12, 20, 12, 13, 8, 17, 4, 9, 7, 18, 3, 17, 6, 11, 17, 10, 9, 4, 10, 1, 3, 1, 16, 10, 15, 20, 16, 3, 12, 17, 1, 14, 12, 10, 8, 10, 9, 14, 8, 6, 6, 13, 4, 16, 10, 9, 9, 4, 10, 15, 9, 8, 6, 3, 4, 18, 17, 12, 13, 4, 15, 5, 4, 13, 4, 10, 12, 4, 18, 12, 13, 6, 4, 17, 14, 3, 17, 16, 17, 1, 15, 1, 10, 1, 17, 16, 10, 14, 1, 5, 1, 10, 4, 3, 9, 10, 13, 16, 4, 9, 15, 4, 10, 10, 8, 3, 19, 11, 9, 15, 12, 17, 17, 6, 3, 1, 10, 8, 15, 1, 6, 18, 13, 4, 6, 19, 4, 18, 1, 3, 9, 17, 6, 1, 6, 16, 20, 6, 17, 15, 12, 3, 8, 1, 8, 8, 19, 13, 13, 9, 6, 3, 13, 18, 18, 10, 1, 18, 10, 16, 16, 15, 3, 9, 9, 3, 1, 9, 20, 3, 3, 9, 10, 8, 1, 4, 1, 17, 9, 18, 18, 10, 9, 1, 10]\",\n          \"[3, 8, 18, 10, 17, 14, 16, 13, 1, 16, 10, 1, 18, 16, 10, 6, 14, 15, 1, 17, 11, 16, 2, 15, 1, 6, 4, 16, 18, 3, 8, 5, 6, 18, 6, 5, 10, 7, 19, 20, 14, 14, 9, 13, 6, 14, 13, 13, 9, 10, 10, 8, 20, 15, 1, 16, 12, 10, 4, 16, 6, 8, 13, 18, 15, 5, 16, 6, 17, 6, 16, 15, 17, 3, 5, 17, 10, 8, 8, 3, 13, 18, 4, 1, 3, 3, 18, 1, 17, 20, 20, 2, 14, 14, 17, 12, 4, 3, 13, 20, 17, 5, 6, 6, 6, 17, 9, 10, 4, 8, 9]\",\n          \"[6, 1, 18, 5, 8, 5, 18, 6, 1, 10, 17, 18, 10, 5, 6, 1, 8, 1, 20, 6, 4, 18, 17, 1, 1, 1, 1, 17, 6, 3, 1, 1, 1, 18, 14, 4, 1, 1, 18, 16, 1, 8, 10, 6, 10, 8, 8, 10, 10, 6, 8, 12, 10, 6, 10, 18, 1, 1, 17, 10]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_masked_sequence_A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 442,\n        \"samples\": [\n          \"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 6, 0, 0, 15, 1, 0, 0, 18, 15, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 4, 6, 10, 4, 1, 16, 9, 1, 1, 18, 10, 4, 17, 1, 13, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 19, 17, 13, 0, 18, 4, 12, 16, 11, 9, 14, 10, 3, 13, 4, 12, 13, 15, 9, 1, 1, 4, 4, 5, 8, 14, 18, 12, 13, 16, 9, 15, 20, 6, 4, 1, 13, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\",\n          \"[15, 17, 10, 9, 4, 10, 4, 15, 4, 10, 14, 13, 15, 14, 7, 10, 19, 20, 5, 4, 20, 20, 17, 6, 12, 12, 18, 6, 10, 5, 11, 9, 11, 12, 0, 0, 8, 20, 16, 0, 0, 0, 0, 8, 0, 15, 0, 0, 0, 0, 4, 12, 0, 0, 0, 0, 0, 0, 0, 1, 10, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 18, 5, 16, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 20, 10, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 18, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\",\n          \"[0, 0, 0, 1, 0, 2, 18, 0, 9, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 6, 3, 12, 0, 1, 6, 2, 17, 16, 1, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 6, 3, 0, 2, 0, 8, 6, 15, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 18, 8, 6, 8, 1, 14]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_masked_sequence_B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 445,\n        \"samples\": [\n          \"[15, 8, 6, 20, 6, 4, 3, 16, 7, 15, 10, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 6, 1, 10, 1, 7, 16, 0, 6, 0, 1, 0, 0, 7, 1, 10, 17, 3, 1, 10, 10, 16, 1, 20, 6, 10, 6, 3, 8, 6, 10, 10, 5, 13, 3, 17, 3, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 10, 18, 0, 0, 15, 6, 1, 9, 10, 10, 14, 1, 16, 10, 18, 10, 17, 10, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 6, 10, 17, 5, 9, 17, 16, 4, 6, 10, 1, 13, 16, 7, 18, 14, 1, 15, 1, 18, 18, 10, 10, 3]\",\n          \"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 13, 20, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 16, 20, 12, 14, 6, 6, 10, 5, 20, 14, 20, 10, 15, 3, 12, 1, 2, 18, 1, 16, 17, 13, 3, 5, 4, 10, 17, 12, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 12, 18, 5, 16, 0, 3, 1, 5, 0, 0, 4, 3, 4, 4, 5, 18, 9, 9, 19, 16, 16, 15, 6, 12, 8, 1, 0, 0, 0, 0, 0, 0, 17, 10, 0, 0, 10, 16, 9, 18, 9, 6, 19, 9, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 9, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\",\n          \"[0, 0, 0, 0, 0, 0, 18, 0, 9, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 5, 6, 3, 12, 17, 1, 6, 2, 17, 16, 1, 6, 13, 0, 5, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 6, 3, 0, 2, 8, 8, 6, 15, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 18, 8, 6, 8, 1, 0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum_tokenized_sequence_A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 452,\n        \"samples\": [\n          \"[15, 5, 17, 3, 15, 18, 18, 10, 8, 17, 6, 6, 6, 16, 6, 10, 6, 15, 1, 17, 1, 18, 15, 10, 1, 1, 4, 6, 1, 9, 10, 16, 10, 18, 3, 18, 16, 16, 4, 6, 10, 4, 1, 16, 9, 1, 1, 18, 10, 4, 17, 1, 13, 3, 1, 4, 18, 10, 17, 17, 18, 1, 3, 18, 16, 3, 4, 1, 14, 18, 4, 1, 20, 18, 17, 1, 17, 17, 4, 15, 5, 6, 15, 8, 3, 6, 5, 5, 12, 12, 1, 6, 8, 4, 6, 9, 14, 12, 13, 17, 4, 16, 5, 17, 1, 1, 4, 5, 3, 9, 18, 18, 16, 8, 12, 10, 15, 6, 18, 5, 10, 6, 10, 4, 9, 18, 10, 18, 8, 22, 30, 8, 28, 12, 32, 6, 11, 18, 18, 12, 17, 1, 16, 18, 6, 6, 8, 15, 6, 8, 6, 12, 14, 16, 6, 20, 1, 1, 1, 9, 7, 6, 18, 18, 12, 10, 34, 30, 24, 32, 2, 36, 8, 40, 12, 30, 40, 12, 16, 30, 16, 12, 1, 8, 1, 13, 6, 1, 8, 19, 17, 13, 11, 18, 4, 12, 16, 11, 9, 14, 10, 3, 13, 4, 12, 13, 15, 9, 1, 1, 4, 4, 5, 8, 14, 18, 12, 13, 16, 9, 15, 20, 6, 4, 1, 13, 4, 8, 1, 1, 18, 18, 1, 5, 10, 10, 16, 6, 6, 2, 32, 40, 36, 24, 2, 34, 36, 18, 13, 8, 3, 6, 6, 14, 16, 1, 1, 20]\",\n          \"[36, 15, 8, 10, 6, 20, 3, 13, 10, 1, 16, 13, 1, 10, 10, 14, 18, 14, 8, 13, 1, 17, 13, 17, 16, 10, 4, 17, 1, 9, 15, 6, 15, 15, 4, 1, 8, 3, 8, 8, 17, 6, 9, 3, 3, 15, 18, 10, 18, 8, 18, 6, 13, 2, 16, 8, 7, 3, 10, 4, 1, 1, 14, 4, 20, 1, 10, 15, 10, 9, 9, 10, 16, 3, 4, 10, 9, 6, 3, 10, 16, 8, 8, 11, 15, 1, 20, 10, 4, 9, 13, 15, 17, 17, 18, 6, 19, 9, 6, 10, 8, 12, 3, 13, 3, 18, 12, 12, 17, 5, 12, 8, 12, 9, 6, 10, 14, 16, 1, 15, 14, 10, 5, 18, 12, 10, 17, 12, 8, 6, 10, 13, 8, 6, 16, 4, 11, 10, 3, 17, 8, 16, 13, 14, 20, 10, 1, 3, 10, 18, 16, 5, 6, 1, 8, 6, 1, 15, 17, 17, 8, 32, 28, 20, 7, 30, 8, 10, 1, 32, 6, 10, 16, 5, 13, 18, 6, 5, 9, 12, 6, 17, 3, 6, 17, 10, 24, 36, 1, 36, 6, 2, 2, 28, 2, 2, 2, 14, 32, 14, 14, 10, 22, 12, 18, 17, 9, 7, 6, 18, 2, 2, 16, 34, 34, 34, 18, 12, 24, 8, 7, 2, 5, 18, 8, 10, 15, 6, 6, 9, 9, 6, 17, 12, 20, 3, 1, 9, 16, 18, 1, 4, 1, 9, 1, 28, 20, 26, 2, 12, 32, 12, 6, 10, 11, 8, 3, 20, 16, 7, 6, 12, 16, 12, 9, 3, 5, 15, 12, 14, 13, 9, 18, 12, 3, 18, 18, 2, 4, 14, 8, 1, 12, 6, 4, 12, 1, 8, 17, 6, 18, 11, 8, 4, 16, 12, 8, 12, 4, 6, 12, 14, 6, 8, 9, 20, 6, 18, 16, 8, 17, 3, 1, 2, 8, 6, 19, 4, 17, 17, 4, 3, 18, 10, 15, 9, 10, 1, 1, 1, 18, 15, 14, 15, 15, 4, 18, 12, 9]\",\n          \"[36, 20, 32, 26, 2, 6, 18, 17, 24, 36, 9, 1, 1, 19, 6, 9, 18, 6, 1, 7, 1, 6, 4, 20, 6, 1, 4, 1, 10, 4, 15, 22, 5, 10, 32, 10, 26, 34, 34, 18, 34, 40, 5, 13, 7, 5, 3, 10, 16, 7, 6, 16, 1, 14, 18, 9, 6, 7, 6, 9, 9, 18, 1, 3, 1, 10, 17, 12, 1, 18, 1, 14, 36, 6, 6, 22, 26, 24, 2, 20, 32, 2, 20, 32, 6, 20, 14, 2, 14, 18, 20, 30, 36, 6, 26, 36, 24, 10, 18, 20, 20, 32, 14, 4, 10, 20, 18, 17, 10, 1, 1, 7, 10, 13, 1, 4, 5, 17, 26, 2, 36, 14, 2, 32, 20, 6, 18, 10, 20, 2, 32, 36, 32, 34, 36, 20, 34, 32, 18, 40, 30]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum_tokenized_sequence_B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 451,\n        \"samples\": [\n          \"[15, 5, 17, 3, 15, 18, 18, 10, 8, 17, 6, 6, 6, 16, 6, 10, 6, 15, 1, 17, 1, 18, 15, 10, 1, 1, 4, 6, 1, 9, 10, 16, 10, 18, 3, 18, 16, 16, 4, 6, 10, 4, 1, 16, 9, 1, 1, 18, 10, 4, 17, 1, 13, 3, 1, 4, 18, 10, 17, 17, 18, 1, 3, 18, 16, 3, 8, 2, 14, 18, 8, 1, 20, 18, 17, 1, 17, 17, 4, 15, 5, 6, 15, 8, 3, 6, 5, 5, 12, 12, 1, 6, 8, 4, 6, 9, 14, 12, 13, 17, 4, 16, 5, 17, 2, 1, 4, 10, 6, 9, 18, 36, 32, 8, 12, 20, 30, 6, 18, 10, 20, 6, 20, 8, 18, 36, 20, 18, 16, 22, 30, 8, 28, 12, 32, 12, 11, 18, 18, 12, 17, 1, 16, 18, 6, 6, 16, 15, 6, 8, 6, 12, 14, 16, 6, 20, 1, 2, 2, 18, 14, 12, 36, 36, 12, 20, 34, 30, 24, 32, 2, 36, 8, 40, 12, 30, 40, 12, 16, 30, 16, 12, 1, 8, 1, 13, 6, 1, 8, 19, 17, 13, 11, 18, 4, 12, 16, 11, 9, 14, 10, 3, 13, 4, 12, 13, 15, 9, 1, 1, 4, 4, 5, 8, 14, 18, 12, 13, 16, 9, 15, 20, 6, 4, 1, 13, 4, 8, 1, 1, 18, 18, 1, 5, 10, 10, 16, 3, 3, 1, 16, 40, 36, 24, 2, 34, 36, 18, 13, 8, 3, 6, 6, 14, 16, 1, 1, 20]\",\n          \"[36, 30, 16, 20, 12, 20, 3, 13, 10, 1, 16, 13, 1, 10, 10, 14, 18, 14, 8, 13, 1, 17, 13, 17, 16, 10, 4, 17, 1, 9, 15, 6, 15, 15, 4, 1, 8, 3, 8, 8, 17, 6, 9, 3, 3, 15, 18, 10, 18, 8, 18, 6, 13, 2, 16, 8, 7, 3, 10, 4, 1, 1, 14, 4, 20, 1, 10, 15, 10, 9, 9, 10, 16, 3, 4, 10, 9, 6, 3, 10, 16, 8, 8, 11, 15, 1, 20, 10, 4, 9, 13, 15, 17, 17, 18, 6, 19, 9, 6, 10, 8, 12, 3, 13, 3, 18, 12, 12, 17, 5, 12, 8, 12, 9, 6, 10, 14, 16, 1, 15, 14, 10, 5, 18, 12, 10, 17, 12, 8, 6, 10, 13, 8, 6, 16, 4, 11, 10, 3, 17, 8, 16, 13, 14, 20, 10, 1, 3, 10, 18, 16, 5, 6, 1, 8, 6, 1, 15, 17, 17, 8, 32, 28, 20, 7, 30, 8, 10, 1, 16, 6, 10, 16, 5, 13, 18, 6, 5, 9, 12, 6, 17, 3, 6, 17, 10, 24, 36, 1, 36, 6, 2, 2, 28, 2, 2, 2, 14, 32, 14, 14, 10, 22, 12, 36, 17, 9, 7, 6, 36, 2, 2, 16, 34, 34, 34, 18, 12, 12, 4, 7, 2, 5, 18, 8, 10, 15, 6, 6, 9, 9, 6, 17, 12, 20, 3, 1, 9, 16, 18, 1, 4, 1, 9, 1, 28, 10, 26, 2, 6, 16, 12, 6, 10, 11, 8, 3, 20, 16, 7, 6, 12, 16, 12, 9, 3, 5, 15, 12, 14, 13, 9, 18, 12, 3, 18, 18, 2, 4, 14, 8, 1, 12, 6, 4, 12, 1, 8, 17, 6, 18, 11, 8, 4, 16, 12, 8, 12, 4, 6, 12, 14, 6, 8, 13, 1, 6, 10, 9, 20, 6, 18, 16, 8, 17, 3, 1, 2, 8, 6, 19, 4, 17, 17, 4, 3, 18, 10, 15, 9, 10, 1, 1, 1, 18, 15, 14, 15, 15, 4, 18, 12]\",\n          \"[18, 10, 32, 26, 2, 6, 18, 34, 24, 36, 18, 2, 2, 38, 12, 18, 36, 12, 2, 14, 2, 12, 8, 40, 12, 2, 8, 1, 10, 4, 15, 11, 5, 10, 16, 5, 13, 17, 17, 9, 17, 20, 5, 13, 7, 5, 3, 10, 16, 7, 12, 16, 2, 14, 18, 18, 12, 14, 12, 18, 18, 36, 2, 6, 2, 20, 34, 24, 2, 36, 2, 14, 36, 6, 6, 11, 13, 12, 2, 10, 16, 1, 10, 16, 3, 10, 7, 1, 7, 9, 10, 15, 18, 3, 13, 18, 12, 5, 9, 10, 10, 16, 7, 2, 10, 10, 18, 34, 20, 2, 2, 14, 20, 26, 2, 8, 10, 34, 26, 2, 36, 7, 1, 16, 10, 3, 9, 5, 10, 1, 16, 18, 16, 17, 18, 10, 17, 16, 9, 20, 15]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 21,\n        \"max\": 500,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          207,\n          240,\n          297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r0l1YXCvOFH"
      },
      "source": [
        "Create dataset class that handles both global sequences and local sequences for protein pairs, and potentially prepares for the inclusion of 3D structural data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32Lx8aF-7PEj"
      },
      "source": [
        "#the base Model (without coordinates at this point):\n",
        "\n",
        "  ### Modeling Interactions:\n",
        "  The mdel could be trained to recognize which amino acids interact by learning representations of local sequences that highlight these interactions. During training, the MLM objective helps the model learn contextual embeddings that are rich in information about which amino acids tend to be near each other and under what structural contexts they interact.\n",
        "\n",
        "  ### Attention Mechanism:\n",
        "   The custom attention mechanism can be used to weigh the importance of different amino acids in the global context when predicting the masked amino acids in the local sequences. This allows your model to focus more on the parts of the global sequences that are relevant to the interactions highlighted by the local sequences.\n",
        "\n",
        "  ### Utilizing Global Sequences:\n",
        "  While the local sequences are your primary interest, the global sequences provide the context necessary for your model to understand the broader environment in which the interactions occur. Even during prediction, you should feed the model the global sequences to utilize the learned context.\n",
        "\n",
        "  #### This modular design not only meets your current requirements but also provides a scalable framework to incorporate additional dimensions of protein sequence data analysis in the future\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\"\"\"\n",
        "try:\n",
        "    # Initialize the ProtBERT tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert')\n",
        "\n",
        "    # Define special tokens for entities\n",
        "    special_tokens = ['[ENTITY1]', '[ENTITY2]']\n",
        "\n",
        "    # Add special tokens to the tokenizer\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})\n",
        "\n",
        "    # Check if the special tokens were added successfully\n",
        "    print(f\"Token '[ENTITY1]' has ID: {tokenizer.convert_tokens_to_ids('[ENTITY1]')}\")\n",
        "    print(f\"Token '[ENTITY2]' has ID: {tokenizer.convert_tokens_to_ids('[ENTITY2]')}\")\n",
        "\n",
        "    # Initialize the ProtBERT model configured for Masked Language Modeling\n",
        "    model = AutoModelForMaskedLM.from_pretrained('Rostlab/prot_bert')\n",
        "    model.resize_token_embeddings(len(tokenizer))  # Adjust the model's embedding size to accommodate new tokens\n",
        "    print('Token embeddings resized to accommodate new tokens.')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred when initializing the tokenizer or model: {e}\")\n",
        "\n",
        "# Helper function to convert numerical token IDs back to their textual representation\n",
        "def ids_to_text(ids):\n",
        "    return ' '.join(tokenizer.convert_ids_to_tokens(ids))\n",
        "\n",
        "# Check the updated size of the tokenizer's vocabulary\n",
        "print(f\"Updated vocabulary size: {len(tokenizer)}\")\n",
        "\n",
        "if '[ENTITY1]' and '[ENTITY2]' in tokenizer.get_vocab():\n",
        "    print(\"[ENTITY1] and [ENTITY2] are in the tokenizer's vocabulary.\")\n",
        "else:\n",
        "   print(\"[ENTITY1] and [ENTITY2] are NOT in the tokenizer's vocabulary.\")\n",
        "\"\"\"\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint_path = '/content/drive/MyDrive/Checkpoints/final_chekpoint.pth'\n",
        "try:\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # Load the state dictionary (adjust the model to fit exactly the checkpoint's structure)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "    print(f\"Missing keys: {missing_keys}\")\n",
        "    print(f\"Unexpected keys: {unexpected_keys}\")\n",
        "\n",
        "    # Move the model to the designated device\n",
        "    model.to(device)\n",
        "    print(\"Model loaded and moved to device:\", device)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Checkpoint file not found at {checkpoint_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the checkpoint: {e}\")\n"
      ],
      "metadata": {
        "id": "E6WJCm3Ne_31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f64c87c-07e6-4f43-ffd9-ae15ba3f4a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token '[ENTITY1]' has ID: 30\n",
            "Token '[ENTITY2]' has ID: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embeddings resized to accommodate new tokens.\n",
            "Updated vocabulary size: 32\n",
            "[ENTITY1] and [ENTITY2] are in the tokenizer's vocabulary.\n",
            "Checkpoint file not found at /content/drive/MyDrive/Checkpoints/final_chekpoint.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApUN1McupeKe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class ProteinInteractionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch Dataset class that handles protein interaction data.\n",
        "    This dataset supports multiple modes to prepare data, including masked and local sequence configurations,\n",
        "    facilitating different training approaches.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512, mask_probability=0.15, modes=None):\n",
        "        \"\"\"\n",
        "        Initializes the ProteinInteractionDataset.\n",
        "        Args:\n",
        "            dataframe (pandas.DataFrame): The dataframe containing protein sequences.\n",
        "            tokenizer (transformers.BertTokenizer): The tokenizer for encoding sequences.\n",
        "            max_length (int): Maximum sequence length to which sequences will be padded/truncated.\n",
        "            mask_probability (float): Probability of masking a token for training masked language models.\n",
        "            modes (list of str): Specifies the modes of data preparation (e.g., 'global_masked', 'local').\n",
        "        \"\"\"\n",
        "        assert 'Sequence_A' in dataframe.columns and 'Sequence_B' in dataframe.columns, \"DataFrame must include 'Sequence_A' and 'Sequence_B' columns.\"\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.mask_probability = mask_probability\n",
        "        self.modes = modes if modes else ['global_masked']\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of items in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves an item by index.\n",
        "        Args:\n",
        "            idx (int): Index of the item.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary of processed features for each mode.\n",
        "        \"\"\"\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        data = {}\n",
        "\n",
        "        for mode in self.modes:\n",
        "            if mode == 'global_masked':\n",
        "                sequence = f\"[CLS] {row['Sequence_A']} [ENTITY1] [SEP] {row['Sequence_B'] } [ENTITY2] [SEP] \"\n",
        "                input_ids, attention_mask, labels = self.random_mask_sequence(sequence)\n",
        "                key_suffix = 'global_masked'\n",
        "            elif mode == 'local':\n",
        "                sequence = f\"[CLS] {row['masked_sequence_A']} [ENTITY1] [SEP] {row['masked_sequence_B'] } [ENTITY2] [SEP]\"\n",
        "                input_ids, attention_mask = self.tokenize_sequence(sequence)\n",
        "                labels = torch.full_like(input_ids, -100)\n",
        "                key_suffix = 'local'\n",
        "\n",
        "            data[f'input_ids_{key_suffix}'] = input_ids\n",
        "            data[f'attention_mask_{key_suffix}'] = attention_mask\n",
        "            data[f'labels_{key_suffix}'] = labels\n",
        "\n",
        "        return data\n",
        "\n",
        "    def tokenize_sequence(self, sequence):\n",
        "        \"\"\"\n",
        "        Tokenizes a sequence using the provided tokenizer.\n",
        "        Args:\n",
        "            sequence (str): The sequence to tokenize.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of tensors (input_ids, attention_mask).\n",
        "        \"\"\"\n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            sequence,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return encoded['input_ids'].squeeze(0), encoded['attention_mask'].squeeze(0)\n",
        "\n",
        "    def random_mask_sequence(self, sequence):\n",
        "        \"\"\"\n",
        "        Randomly masks tokens in a sequence based on the specified mask probability.\n",
        "        Args:\n",
        "            sequence (str): The sequence to mask.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of tensors (input_ids, attention_mask, labels).\n",
        "        \"\"\"\n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            sequence,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoded['input_ids'].squeeze(0)\n",
        "        labels = torch.full_like(input_ids, -100)\n",
        "\n",
        "        # Decide where to mask tokens\n",
        "        mask_indices = (torch.rand(input_ids.shape) < self.mask_probability) & (input_ids != self.tokenizer.pad_token_id)\n",
        "        labels[mask_indices] = input_ids[mask_indices]\n",
        "\n",
        "        # 80% of the time replace with [MASK]\n",
        "        actual_mask = mask_indices & (torch.rand(input_ids.shape) < 0.8)\n",
        "        input_ids[actual_mask] = self.tokenizer.mask_token_id\n",
        "\n",
        "        # 20% of the time replace with a random token\n",
        "        random_tokens = torch.randint(2, self.tokenizer.vocab_size, input_ids.shape)\n",
        "        input_ids[mask_indices & ~actual_mask] = random_tokens[mask_indices & ~actual_mask]\n",
        "\n",
        "        return input_ids, torch.ones_like(input_ids), labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    global_input_ids = [item['global_input_ids'] for item in batch]\n",
        "    global_attention_masks = [item['global_attention_mask'] for item in batch]\n",
        "    local_input_ids = [item['local_input_ids'] for item in batch]\n",
        "    local_attention_masks = [item['local_attention_mask'] for item in batch]\n",
        "\n",
        "    # Pad sequences within each batch to the longest sequence in that batch\n",
        "    global_input_ids_padded = pad_sequence(global_input_ids, batch_first=True, padding_value=0)\n",
        "    global_attention_masks_padded = pad_sequence(global_attention_masks, batch_first=True, padding_value=0)\n",
        "    local_input_ids_padded = pad_sequence(local_input_ids, batch_first=True, padding_value=0)\n",
        "    local_attention_masks_padded = pad_sequence(local_attention_masks, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {\n",
        "        'global_input_ids': global_input_ids_padded,\n",
        "        'global_attention_mask': global_attention_masks_padded,\n",
        "        'local_input_ids': local_input_ids_padded,\n",
        "        'local_attention_mask': local_attention_masks_padded\n",
        "    }\n"
      ],
      "metadata": {
        "id": "uRffIAsuVZo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Validation data creator:"
      ],
      "metadata": {
        "id": "GxmLUb2ERCBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into 80% training and 20% testing\n",
        "train_df, test_df = train_test_split(pairs_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Assuming ProteinInteractionDataset and tokenizer are correctly implemented and initialized\n",
        "train_dataset = ProteinInteractionDataset(train_df, tokenizer)\n",
        "test_dataset = ProteinInteractionDataset(test_df, tokenizer)\n",
        "\n",
        "# DataLoader setup, possibly with a custom collation function if your dataset needs it\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn if 'collate_fn' in globals() else None)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn if 'collate_fn' in globals() else None)\n"
      ],
      "metadata": {
        "id": "yeDTEYUNRBEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pretraining the bert model\n"
      ],
      "metadata": {
        "id": "cQ7xnO7FseKP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSaaU5j6rHdO"
      },
      "source": [
        "#main class for training:\n",
        "  1. Process two sets of sequences (global and local) using BERT to extract contextual embeddings.\n",
        "  2. Integrate these two sets of embeddings using a custom attention mechanism that focuses on relevant parts of the global features for each part of the local features.\n",
        "  3. Predict an output (like interaction sites or effects) using the combined features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2qm1dRzz2pr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class SequenceProcessor(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        \"\"\"\n",
        "        Initialize the sequence processor with a pre-trained model.\n",
        "        :param model: A pre-trained model, typically a fine-tuned ProtBERT.\n",
        "        \"\"\"\n",
        "        super(SequenceProcessor, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass to process sequences through the model.\n",
        "        Extracts last hidden state as the feature representation of the input.\n",
        "        :param input_ids: Input tokens IDs to the model.\n",
        "        :param attention_mask: Mask to avoid processing padding as part of the input.\n",
        "        \"\"\"\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state\n",
        "\n",
        "class CustomAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        \"\"\"\n",
        "        Custom attention mechanism that models relationships between features.\n",
        "        :param hidden_size: Size of the hidden layers in the ProtBERT model.\n",
        "        \"\"\"\n",
        "        super(CustomAttention, self).__init__()\n",
        "        self.key_layer = nn.Linear(hidden_size, hidden_size)\n",
        "        self.query_layer = nn.Linear(hidden_size, hidden_size)\n",
        "        self.value_layer = nn.Linear(hidden_size, hidden_size)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.context_layer = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, global_features, local_features):\n",
        "        \"\"\"\n",
        "        Forward pass through the attention mechanism.\n",
        "        Calculates attention scores and returns a context vector.\n",
        "        :param global_features: Features from the global sequence processor.\n",
        "        :param local_features: Features from the local sequence processor.\n",
        "        \"\"\"\n",
        "        keys = self.key_layer(global_features)\n",
        "        queries = self.query_layer(local_features)\n",
        "        values = self.value_layer(global_features)\n",
        "        attention_scores = torch.matmul(queries, keys.transpose(-2, -1)) / (keys.size(-1) ** 0.5)\n",
        "        attention_weights = self.softmax(attention_scores)\n",
        "        context = torch.matmul(attention_weights, values)\n",
        "        processed_context = self.context_layer(context)\n",
        "        return processed_context\n",
        "\n",
        "class ProteinInteractionModel(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        \"\"\"\n",
        "        Main model to predict protein interactions using ProtBERT with custom attention.\n",
        "        :param model_path: Path to the fine-tuned ProtBERT model.\n",
        "        \"\"\"\n",
        "        super(ProteinInteractionModel, self).__init__()\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModel.from_pretrained(model_path)\n",
        "        hidden_size = self.model.config.hidden_size\n",
        "        self.global_processor = SequenceProcessor(self.model)\n",
        "        self.local_processor = SequenceProcessor(self.model)\n",
        "        self.attention = CustomAttention(hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, self.tokenizer.vocab_size)\n",
        "\n",
        "    def forward(self, input_ids_global, attention_mask_global, input_ids_local=None, attention_mask_local=None):\n",
        "        \"\"\"\n",
        "        Forward pass for the entire model. Processes both global and local features,\n",
        "        applies attention between them, and produces prediction scores.\n",
        "        :param input_ids_global: Input IDs for the global sequence.\n",
        "        :param attention_mask_global: Attention mask for the global sequence.\n",
        "        :param input_ids_local: Input IDs for the local sequence (used in training).\n",
        "        :param attention_mask_local: Attention mask for the local sequence (used in training).\n",
        "        \"\"\"\n",
        "        global_features = self.global_processor(input_ids_global, attention_mask_global)\n",
        "        if self.training and input_ids_local is not None:\n",
        "            local_features = self.local_processor(input_ids_local, attention_mask_local)\n",
        "        else:\n",
        "            local_features = global_features  # Use global features for local prediction during inference\n",
        "        context_features = self.attention(global_features, local_features)\n",
        "        prediction_scores = self.output_layer(context_features)\n",
        "        return prediction_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouA_WiDqRUqr"
      },
      "source": [
        "# Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5RnrPjjRhip"
      },
      "source": [
        "#Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def __getitem__(self, idx):\n",
        "    # Extract the row from the dataframe\n",
        "    row = self.dataframe.iloc[idx]\n",
        "\n",
        "    # Prepare global and local input sequences\n",
        "    global_input = f\"[CLS] {row['Sequence_A']} [ENTITY1] [SEP] {row['Sequence_B']} [ENTITY2] [SEP]\"\n",
        "    local_input = f\"[CLS] {row['masked_sequence_A']} [ENTITY1] [SEP] {row['masked_sequence_B']} [ENTITY2] [SEP]\"\n",
        "\n",
        "    # Tokenize sequences\n",
        "    global_features = self.tokenize_sequence(global_input)\n",
        "    local_features = self.tokenize_sequence(local_input)\n",
        "\n",
        "    # Debugging: Print shapes and sample contents\n",
        "    print(\"Debugging __getitem__:\")\n",
        "    print(f\"Index: {idx}\")\n",
        "    print(f\"Global Input IDs Shape: {global_features['input_ids'].shape}, Sample: {global_features['input_ids'][:10]}\")\n",
        "    print(f\"Local Input IDs Shape: {local_features['input_ids'].shape}, Sample: {local_features['input_ids'][:10]}\")\n",
        "\n",
        "    # Return the processed features\n",
        "    return {\n",
        "        'global_input_ids': global_features['input_ids'],\n",
        "        'global_attention_mask': global_features['attention_mask'],\n",
        "        'local_input_ids': local_features['input_ids'],\n",
        "        'local_attention_mask': local_features['attention_mask']\n",
        "    }\n"
      ],
      "metadata": {
        "id": "k_01cVFMDm4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l02vBOukRiqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "19183ff2-9b68-4359-9a8d-9bb1027e8357"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'row' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-ba20f010c76e>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mglobal_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'global_input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlocal_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-0252aa800500>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# Prepare global and local input sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mglobal_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"[CLS] {row['Sequence_A']} [ENTITY1] [SEP] {row['Sequence_B']} [ENTITY2] [SEP]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mlocal_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"[CLS] {row['masked_sequence_A']} [ENTITY1] [SEP] {row['masked_sequence_B']} [ENTITY2] [SEP]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assume `ProteinInteractionModel` and `ProteinInteractionDataset` are defined in your code.\n",
        "# Assume `collate_fn` is your custom collate function for handling batches.\n",
        "\n",
        "# Setup Dataset and DataLoader\n",
        "dataset = ProteinInteractionDataset(dataframe=pairs_df, tokenizer=tokenizer)  # Using the pre-loaded tokenizer\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Model and tokenizer are already initialized and loaded from the previous script segment\n",
        "# Ensure the model is on the correct device\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to the appropriate device\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        global_input_ids = batch['global_input_ids'].to(device)\n",
        "        local_input_ids = batch['local_input_ids'].to(device)\n",
        "        attention_mask_global = batch['global_attention_mask'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(global_input_ids, attention_mask=attention_mask_global)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Ensure the target labels are the same shape as the logits output\n",
        "        # Reshape local_input_ids to be [batch_size * sequence_length]\n",
        "        # This requires local_input_ids initially to be [batch_size, sequence_length]\n",
        "        if local_input_ids.dim() == 2:\n",
        "            local_input_ids = local_input_ids.view(-1)  # Flatten the local_input_ids\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), local_input_ids)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Average Loss: {total_loss / len(data_loader)}')\n",
        "\n",
        "# Optionally save the model after training\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/SecondModel.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q1g5M4YXifqa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}